{"noir_version":"0.35.0+b848cc128d2dc2b461581f21a35509a1af9065a7-x8664","hash":4066284655051901698,"abi":{"parameters":[{"name":"blockheader_serd","type":{"kind":"array","length":24,"type":{"kind":"field"}},"visibility":"public"},{"name":"nsk_m","type":{"kind":"array","length":2,"type":{"kind":"field"}},"visibility":"private"},{"name":"note_content","type":{"kind":"array","length":3,"type":{"kind":"field"}},"visibility":"private"},{"name":"contract_address_as_field","type":{"kind":"field"},"visibility":"public"},{"name":"nonce","type":{"kind":"field"},"visibility":"private"},{"name":"storage_slot","type":{"kind":"field"},"visibility":"private"},{"name":"witness_membership_serd","type":{"kind":"array","length":33,"type":{"kind":"field"}},"visibility":"private"},{"name":"low_nullifier_membership_witness_serd","type":{"kind":"array","length":24,"type":{"kind":"field"}},"visibility":"private"},{"name":"debug_notehash","type":{"kind":"field"},"visibility":"private"},{"name":"debug_nsk_app","type":{"kind":"field"},"visibility":"private"}],"return_type":null,"error_types":{}},"bytecode":"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","debug_symbols":"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","file_map":{"24":{"source":"use crate::ops::arith::{Add, Sub, Neg};\nuse crate::cmp::Eq;\n\n/// A point on the embedded elliptic curve\n/// By definition, the base field of the embedded curve is the scalar field of the proof system curve, i.e the Noir Field.\n/// x and y denotes the Weierstrass coordinates of the point, if is_infinite is false.\npub struct EmbeddedCurvePoint {\n    x: Field,\n    y: Field,\n    is_infinite: bool\n}\n\nimpl EmbeddedCurvePoint {\n    /// Elliptic curve point doubling operation\n    /// returns the doubled point of a point P, i.e P+P\n    pub fn double(self) -> EmbeddedCurvePoint {\n        embedded_curve_add(self, self)\n    }\n\n    /// Returns the null element of the curve; 'the point at infinity'\n    pub fn point_at_infinity() -> EmbeddedCurvePoint {\n        EmbeddedCurvePoint { x: 0, y: 0, is_infinite: true }\n    }\n}\n\nimpl Add for EmbeddedCurvePoint {\n    /// Adds two points P+Q, using the curve addition formula, and also handles point at infinity\n    fn add(self, other: EmbeddedCurvePoint) -> EmbeddedCurvePoint {\n        embedded_curve_add(self, other)\n    }\n}\n\nimpl Sub for EmbeddedCurvePoint {\n    /// Points subtraction operation, using addition and negation\n    fn sub(self, other: EmbeddedCurvePoint) -> EmbeddedCurvePoint {\n        self + other.neg()\n    }\n}\n\nimpl Neg for EmbeddedCurvePoint {\n    /// Negates a point P, i.e returns -P, by negating the y coordinate.\n    /// If the point is at infinity, then the result is also at infinity.\n    fn neg(self) -> EmbeddedCurvePoint {\n        EmbeddedCurvePoint { x: self.x, y: -self.y, is_infinite: self.is_infinite }\n    }\n}\n\nimpl Eq for EmbeddedCurvePoint {\n    /// Checks whether two points are equal\n    fn eq(self: Self, b: EmbeddedCurvePoint) -> bool {\n        (self.is_infinite & b.is_infinite)\n            | ((self.is_infinite == b.is_infinite) & (self.x == b.x) & (self.y == b.y))\n    }\n}\n\n/// Scalar for the embedded curve represented as low and high limbs\n/// By definition, the scalar field of the embedded curve is base field of the proving system curve.\n/// It may not fit into a Field element, so it is represented with two Field elements; its low and high limbs.\npub struct EmbeddedCurveScalar {\n    lo: Field,\n    hi: Field,\n}\n\nimpl EmbeddedCurveScalar {\n    pub fn new(lo: Field, hi: Field) -> Self {\n        EmbeddedCurveScalar { lo, hi }\n    }\n\n    #[field(bn254)]\n    pub fn from_field(scalar: Field) -> EmbeddedCurveScalar {\n        let (a,b) = crate::field::bn254::decompose(scalar);\n        EmbeddedCurveScalar { lo: a, hi: b }\n    }\n\n    //Bytes to scalar: take the first (after the specified offset) 16 bytes of the input as the lo value, and the next 16 bytes as the hi value\n    #[field(bn254)]\n    pub(crate) fn from_bytes(bytes: [u8; 64], offset: u32) -> EmbeddedCurveScalar {\n        let mut v = 1;\n        let mut lo = 0 as Field;\n        let mut hi = 0 as Field;\n        for i in 0..16 {\n            lo = lo + (bytes[offset+31 - i] as Field) * v;\n            hi = hi + (bytes[offset+15 - i] as Field) * v;\n            v = v * 256;\n        }\n        let sig_s = crate::embedded_curve_ops::EmbeddedCurveScalar { lo, hi };\n        sig_s\n    }\n}\n\nimpl Eq for EmbeddedCurveScalar {\n    fn eq(self, other: Self) -> bool {\n        (other.hi == self.hi) & (other.lo == self.lo)\n    }\n}\n\n// Computes a multi scalar multiplication over the embedded curve.\n// For bn254, We have Grumpkin and Baby JubJub.\n// For bls12-381, we have JubJub and Bandersnatch.\n//\n// The embedded curve being used is decided by the \n// underlying proof system.\n// docs:start:multi_scalar_mul\npub fn multi_scalar_mul<let N: u32>(\n    points: [EmbeddedCurvePoint; N],\n    scalars: [EmbeddedCurveScalar; N]\n) -> EmbeddedCurvePoint\n// docs:end:multi_scalar_mul\n{\n    let point_array = multi_scalar_mul_array_return(points, scalars);\n    EmbeddedCurvePoint { x: point_array[0], y: point_array[1], is_infinite: point_array[2] as bool }\n}\n\n#[foreign(multi_scalar_mul)]\nfn multi_scalar_mul_array_return<let N: u32>(points: [EmbeddedCurvePoint; N], scalars: [EmbeddedCurveScalar; N]) -> [Field; 3] {}\n\n#[foreign(multi_scalar_mul)]\npub(crate) fn multi_scalar_mul_slice(points: [EmbeddedCurvePoint], scalars: [EmbeddedCurveScalar]) -> [Field; 3] {}\n\n// docs:start:fixed_base_scalar_mul\npub fn fixed_base_scalar_mul(scalar: EmbeddedCurveScalar) -> EmbeddedCurvePoint\n// docs:end:fixed_base_scalar_mul\n{\n    let g1 = EmbeddedCurvePoint { x: 1, y: 17631683881184975370165255887551781615748388533673675138860, is_infinite: false };\n    multi_scalar_mul([g1], [scalar])\n}\n\n/// This function only assumes that the points are on the curve\n/// It handles corner cases around the infinity point causing some overhead compared to embedded_curve_add_not_nul and embedded_curve_add_unsafe\n// This is a hack because returning an `EmbeddedCurvePoint` from a foreign function in brillig returns a [BrilligVariable::SingleAddr; 2] rather than BrilligVariable::BrilligArray\n// as is defined in the brillig bytecode format. This is a workaround which allows us to fix this without modifying the serialization format.\n// docs:start:embedded_curve_add\npub fn embedded_curve_add(point1: EmbeddedCurvePoint, point2: EmbeddedCurvePoint) -> EmbeddedCurvePoint {\n    // docs:end:embedded_curve_add\n    let x_coordinates_match = point1.x == point2.x;\n    let y_coordinates_match = point1.y == point2.y;\n    let double_predicate = (x_coordinates_match & y_coordinates_match);\n    let infinity_predicate = (x_coordinates_match & !y_coordinates_match);\n    let point1_1 = EmbeddedCurvePoint { x: point1.x + (x_coordinates_match as Field), y: point1.y, is_infinite: x_coordinates_match };\n    // point1_1 is guaranteed to have a different abscissa than point2\n    let mut result = embedded_curve_add_unsafe(point1_1, point2);\n    result.is_infinite = x_coordinates_match;\n\n    // dbl if x_match, y_match\n    let double = embedded_curve_add_unsafe(point1, point1);\n    result = if double_predicate { double } else { result };\n\n    // infinity if x_match, !y_match\n    if point1.is_infinite {\n        result= point2;\n    }\n    if point2.is_infinite {\n        result = point1;\n    }\n    let mut result_is_infinity = infinity_predicate & (!point1.is_infinite & !point2.is_infinite);\n    result.is_infinite = result_is_infinity | (point1.is_infinite & point2.is_infinite);\n    result\n}\n\n#[foreign(embedded_curve_add)]\nfn embedded_curve_add_array_return(_point1: EmbeddedCurvePoint, _point2: EmbeddedCurvePoint) -> [Field; 3] {}\n\n/// This function assumes that:\n/// The points are on the curve, and\n/// The points don't share an x-coordinate, and\n/// Neither point is the infinity point.\n/// If it is used with correct input, the function ensures the correct non-zero result is returned.\n/// Except for points on the curve, the other assumptions are checked by the function. It will cause assertion failure if they are not respected.\npub fn embedded_curve_add_not_nul(point1: EmbeddedCurvePoint, point2: EmbeddedCurvePoint) -> EmbeddedCurvePoint {\n    assert(point1.x != point2.x);\n    assert(!point1.is_infinite);\n    assert(!point2.is_infinite);\n    embedded_curve_add_unsafe(point1, point2)\n}\n\n/// Unsafe ec addition\n/// If the inputs are the same, it will perform a doubling, but only if point1 and point2 are the same variable.\n/// If they have the same value but are different variables, the result will be incorrect because in this case\n/// it assumes (but does not check) that the points' x-coordinates are not equal.\n/// It also assumes neither point is the infinity point.\npub fn embedded_curve_add_unsafe(point1: EmbeddedCurvePoint, point2: EmbeddedCurvePoint) -> EmbeddedCurvePoint {\n    let point_array = embedded_curve_add_array_return(point1, point2);\n    let x = point_array[0];\n    let y = point_array[1];\n\n    EmbeddedCurvePoint { x, y, is_infinite: false }\n}\n","path":"std/embedded_curve_ops.nr"},"25":{"source":"use crate::runtime::is_unconstrained;\n\n// The low and high decomposition of the field modulus\nglobal PLO: Field = 53438638232309528389504892708671455233;\nglobal PHI: Field = 64323764613183177041862057485226039389;\n\npub(crate) global TWO_POW_128: Field = 0x100000000000000000000000000000000;\n\n// Decomposes a single field into two 16 byte fields.\nfn compute_decomposition(x: Field) -> (Field, Field) {\n    let x_bytes: [u8; 32] = x.to_le_bytes();\n\n    let mut low: Field = 0;\n    let mut high: Field = 0;\n\n    let mut offset = 1;\n    for i in 0..16 {\n        low += (x_bytes[i] as Field) * offset;\n        high += (x_bytes[i + 16] as Field) * offset;\n        offset *= 256;\n    }\n\n    (low, high)\n}\n\nunconstrained pub(crate) fn decompose_hint(x: Field) -> (Field, Field) {\n    compute_decomposition(x)\n}\n\nfn compute_lt(x: Field, y: Field, num_bytes: u32) -> bool {\n    let x_bytes: [u8; 32] = x.to_le_bytes();\n    let y_bytes: [u8; 32] = y.to_le_bytes();\n    let mut x_is_lt = false;\n    let mut done = false;\n    for i in 0..num_bytes {\n        if (!done) {\n            let x_byte = x_bytes[num_bytes - 1 - i];\n            let y_byte = y_bytes[num_bytes - 1 - i];\n            let bytes_match = x_byte == y_byte;\n            if !bytes_match {\n                x_is_lt = x_byte < y_byte;\n                done = true;\n            }\n        }\n    }\n    x_is_lt\n}\n\nfn compute_lte(x: Field, y: Field, num_bytes: u32) -> bool {\n    if x == y {\n        true\n    } else {\n        compute_lt(x, y, num_bytes)\n    }\n}\n\nunconstrained fn lt_32_hint(x: Field, y: Field) -> bool {\n    compute_lt(x, y, 32)\n}\n\nunconstrained fn lte_16_hint(x: Field, y: Field) -> bool {\n    compute_lte(x, y, 16)\n}\n\n// Assert that (alo > blo && ahi >= bhi) || (alo <= blo && ahi > bhi)\nfn assert_gt_limbs(a: (Field, Field), b: (Field, Field)) {\n    let (alo, ahi) = a;\n    let (blo, bhi) = b;\n    unsafe {\n        let borrow = lte_16_hint(alo, blo);\n\n        let rlo = alo - blo - 1 + (borrow as Field) * TWO_POW_128;\n        let rhi = ahi - bhi - (borrow as Field);\n\n        rlo.assert_max_bit_size(128);\n        rhi.assert_max_bit_size(128);\n    }\n}\n\n/// Decompose a single field into two 16 byte fields.\npub fn decompose(x: Field) -> (Field, Field) {\n    if is_unconstrained() {\n        compute_decomposition(x)\n    } else {\n        unsafe {\n            // Take hints of the decomposition\n            let (xlo, xhi) = decompose_hint(x);\n\n            // Range check the limbs\n            xlo.assert_max_bit_size(128);\n            xhi.assert_max_bit_size(128);\n\n            // Check that the decomposition is correct\n            assert_eq(x, xlo + TWO_POW_128 * xhi);\n\n            // Assert that the decomposition of P is greater than the decomposition of x\n            assert_gt_limbs((PLO, PHI), (xlo, xhi));\n            (xlo, xhi)\n        }\n    }\n}\n\npub fn assert_gt(a: Field, b: Field) {\n    if is_unconstrained() {\n        assert(compute_lt(b, a, 32));\n    } else {\n        // Decompose a and b\n        let a_limbs = decompose(a);\n        let b_limbs = decompose(b);\n\n        // Assert that a_limbs is greater than b_limbs\n        assert_gt_limbs(a_limbs, b_limbs)\n    }\n}\n\npub fn assert_lt(a: Field, b: Field) {\n    assert_gt(b, a);\n}\n\npub fn gt(a: Field, b: Field) -> bool {\n    if is_unconstrained() {\n        compute_lt(b, a, 32)\n    } else if a == b {\n        false\n    } else {\n        // Take a hint of the comparison and verify it\n        unsafe {\n            if lt_32_hint(a, b) {\n                assert_gt(b, a);\n                false\n            } else {\n                assert_gt(a, b);\n                true\n            }\n        }\n    }\n}\n\npub fn lt(a: Field, b: Field) -> bool {\n    gt(b, a)\n}\n\nmod tests {\n    // TODO: Allow imports from \"super\"\n    use crate::field::bn254::{decompose, compute_lt, assert_gt, gt, TWO_POW_128, compute_lte, PLO, PHI};\n\n    #[test]\n    fn check_decompose() {\n        assert_eq(decompose(TWO_POW_128), (0, 1));\n        assert_eq(decompose(TWO_POW_128 + 0x1234567890), (0x1234567890, 1));\n        assert_eq(decompose(0x1234567890), (0x1234567890, 0));\n    }\n\n    #[test]\n    unconstrained fn check_decompose_unconstrained() {\n        assert_eq(decompose(TWO_POW_128), (0, 1));\n        assert_eq(decompose(TWO_POW_128 + 0x1234567890), (0x1234567890, 1));\n        assert_eq(decompose(0x1234567890), (0x1234567890, 0));\n    }\n\n    #[test]\n    fn check_compute_lt() {\n        assert(compute_lt(0, 1, 16));\n        assert(compute_lt(0, 0x100, 16));\n        assert(compute_lt(0x100, TWO_POW_128 - 1, 16));\n        assert(!compute_lt(0, TWO_POW_128, 16));\n    }\n\n    #[test]\n    fn check_compute_lte() {\n        assert(compute_lte(0, 1, 16));\n        assert(compute_lte(0, 0x100, 16));\n        assert(compute_lte(0x100, TWO_POW_128 - 1, 16));\n        assert(!compute_lte(0, TWO_POW_128, 16));\n\n        assert(compute_lte(0, 0, 16));\n        assert(compute_lte(0x100, 0x100, 16));\n        assert(compute_lte(TWO_POW_128 - 1, TWO_POW_128 - 1, 16));\n        assert(compute_lte(TWO_POW_128, TWO_POW_128, 16));\n    }\n\n    #[test]\n    fn check_assert_gt() {\n        assert_gt(1, 0);\n        assert_gt(0x100, 0);\n        assert_gt((0 - 1), (0 - 2));\n        assert_gt(TWO_POW_128, 0);\n        assert_gt(0 - 1, 0);\n    }\n\n    #[test]\n    unconstrained fn check_assert_gt_unconstrained() {\n        assert_gt(1, 0);\n        assert_gt(0x100, 0);\n        assert_gt((0 - 1), (0 - 2));\n        assert_gt(TWO_POW_128, 0);\n        assert_gt(0 - 1, 0);\n    }\n\n    #[test]\n    fn check_gt() {\n        assert(gt(1, 0));\n        assert(gt(0x100, 0));\n        assert(gt((0 - 1), (0 - 2)));\n        assert(gt(TWO_POW_128, 0));\n        assert(!gt(0, 0));\n        assert(!gt(0, 0x100));\n        assert(gt(0 - 1, 0 - 2));\n        assert(!gt(0 - 2, 0 - 1));\n    }\n\n    #[test]\n    unconstrained fn check_gt_unconstrained() {\n        assert(gt(1, 0));\n        assert(gt(0x100, 0));\n        assert(gt((0 - 1), (0 - 2)));\n        assert(gt(TWO_POW_128, 0));\n        assert(!gt(0, 0));\n        assert(!gt(0, 0x100));\n        assert(gt(0 - 1, 0 - 2));\n        assert(!gt(0 - 2, 0 - 1));\n    }\n\n    #[test]\n    fn check_plo_phi() {\n        assert_eq(PLO + PHI * TWO_POW_128, 0);\n        let p_bytes = crate::field::modulus_le_bytes();\n        let mut p_low: Field = 0;\n        let mut p_high: Field = 0;\n\n        let mut offset = 1;\n        for i in 0..16 {\n            p_low += (p_bytes[i] as Field) * offset;\n            p_high += (p_bytes[i + 16] as Field) * offset;\n            offset *= 256;\n        }\n        assert_eq(p_low, PLO);\n        assert_eq(p_high, PHI);\n    }\n}\n","path":"std/field/bn254.nr"},"26":{"source":"pub mod bn254;\nuse bn254::lt as bn254_lt;\nuse crate::runtime::is_unconstrained;\n\nimpl Field {\n    /// Asserts that `self` can be represented in `bit_size` bits.\n    ///\n    /// # Failures\n    /// Causes a constraint failure for `Field` values exceeding `2^{bit_size}`.\n    // docs:start:assert_max_bit_size\n    pub fn assert_max_bit_size(self, bit_size: u32) {\n        // docs:end:assert_max_bit_size\n        crate::assert_constant(bit_size);\n        assert(bit_size < modulus_num_bits() as u32);\n        self.__assert_max_bit_size(bit_size);\n    }\n\n    #[builtin(apply_range_constraint)]\n    fn __assert_max_bit_size(self, bit_size: u32) {}\n\n    /// Decomposes `self` into its little endian bit decomposition as a `[u1; N]` array.\n    /// This slice will be zero padded should not all bits be necessary to represent `self`.\n    /// \n    /// # Failures\n    /// Causes a constraint failure for `Field` values exceeding `2^N` as the resulting slice will not\n    /// be able to represent the original `Field`.\n    ///\n    /// # Safety\n    /// Values of `N` equal to or greater than the number of bits necessary to represent the `Field` modulus\n    /// (e.g. 254 for the BN254 field) allow for multiple bit decompositions. This is due to how the `Field` will\n    /// wrap around due to overflow when verifying the decomposition.\n    #[builtin(to_le_bits)]\n    // docs:start:to_le_bits\n    pub fn to_le_bits<let N: u32>(self: Self) -> [u1; N] {}\n    // docs:end:to_le_bits\n\n    /// Decomposes `self` into its big endian bit decomposition as a `[u1; N]` array.\n    /// This array will be zero padded should not all bits be necessary to represent `self`.\n    /// \n    /// # Failures\n    /// Causes a constraint failure for `Field` values exceeding `2^N` as the resulting slice will not\n    /// be able to represent the original `Field`.\n    ///\n    /// # Safety\n    /// Values of `N` equal to or greater than the number of bits necessary to represent the `Field` modulus\n    /// (e.g. 254 for the BN254 field) allow for multiple bit decompositions. This is due to how the `Field` will\n    /// wrap around due to overflow when verifying the decomposition.\n    #[builtin(to_be_bits)]\n     // docs:start:to_be_bits\n    pub fn to_be_bits<let N: u32>(self: Self) -> [u1; N] {}\n    // docs:end:to_be_bits\n\n    /// Decomposes `self` into its little endian byte decomposition as a `[u8;N]` array\n    /// This array will be zero padded should not all bytes be necessary to represent `self`.\n    /// \n    /// # Failures\n    ///  The length N of the array must be big enough to contain all the bytes of the 'self', \n    ///  and no more than the number of bytes required to represent the field modulus\n    ///\n    /// # Safety\n    /// The result is ensured to be the canonical decomposition of the field element\n    // docs:start:to_le_bytes\n    pub fn to_le_bytes<let N: u32>(self: Self) -> [u8; N] {\n        // docs:end:to_le_bytes\n        // Compute the byte decomposition\n        let bytes = self.to_le_radix(256);\n\n        if !is_unconstrained() {\n            // Ensure that the byte decomposition does not overflow the modulus\n            let  p = modulus_le_bytes();\n            assert(bytes.len() <= p.len());\n            let mut ok = bytes.len() != p.len();\n            for i in 0..N {\n                if !ok {\n                    if (bytes[N - 1 - i] != p[N - 1 - i]) {\n                        assert(bytes[N - 1 - i] < p[N - 1 - i]);\n                        ok = true;\n                    }\n                }\n            }\n            assert(ok);\n        }\n        bytes\n    }\n\n    /// Decomposes `self` into its big endian byte decomposition as a `[u8;N]` array of length required to represent the field modulus\n    /// This array will be zero padded should not all bytes be necessary to represent `self`.\n    /// \n    /// # Failures\n    ///  The length N of the array must be big enough to contain all the bytes of the 'self', \n    ///  and no more than the number of bytes required to represent the field modulus\n    ///\n    /// # Safety\n    /// The result is ensured to be the canonical decomposition of the field element\n    // docs:start:to_be_bytes\n    pub fn to_be_bytes<let N: u32>(self: Self) -> [u8; N] {\n        // docs:end:to_be_bytes\n        // Compute the byte decomposition\n        let bytes = self.to_be_radix(256);\n\n        if !is_unconstrained() {\n            // Ensure that the byte decomposition does not overflow the modulus\n            let  p = modulus_be_bytes();\n            assert(bytes.len() <= p.len());\n            let mut ok = bytes.len() != p.len();\n            for i in 0..N {\n                if !ok {\n                    if (bytes[i] != p[i]) {\n                        assert(bytes[i] < p[i]);\n                        ok = true;\n                    }\n                }\n            }\n            assert(ok);\n        }\n        bytes\n    }\n\n    // docs:start:to_le_radix\n    pub fn to_le_radix<let N: u32>(self: Self, radix: u32) -> [u8; N] {\n        crate::assert_constant(radix);\n        self.__to_le_radix(radix)\n    }\n    // docs:end:to_le_radix\n\n    // docs:start:to_be_radix\n    pub fn to_be_radix<let N: u32>(self: Self, radix: u32) -> [u8; N] {\n        crate::assert_constant(radix);\n        self.__to_be_radix(radix)\n    }\n    // docs:end:to_be_radix\n\n    // `_radix` must be less than 256\n    #[builtin(to_le_radix)]\n    fn __to_le_radix<let N: u32>(self, radix: u32) -> [u8; N] {}\n\n    #[builtin(to_be_radix)]\n    fn __to_be_radix<let N: u32>(self, radix: u32) -> [u8; N] {}\n\n    // Returns self to the power of the given exponent value.\n    // Caution: we assume the exponent fits into 32 bits\n    // using a bigger bit size impacts negatively the performance and should be done only if the exponent does not fit in 32 bits\n    pub fn pow_32(self, exponent: Field) -> Field {\n        let mut r: Field = 1;\n        let b: [u1; 32] = exponent.to_le_bits();\n\n        for i in 1..33 {\n            r *= r;\n            r = (b[32-i] as Field) * (r * self) + (1 - b[32-i] as Field) * r;\n        }\n        r\n    }\n\n    // Parity of (prime) Field element, i.e. sgn0(x mod p) = 0 if x `elem` {0, ..., p-1} is even, otherwise sgn0(x mod p) = 1.\n    pub fn sgn0(self) -> u1 {\n        self as u1\n    }\n\n    pub fn lt(self, another: Field) -> bool {\n        if crate::compat::is_bn254() {\n            bn254_lt(self, another)\n        } else {\n            lt_fallback(self, another)\n        }\n    }\n\n    /// Convert a little endian byte array to a field element.\n    /// If the provided byte array overflows the field modulus then the Field will silently wrap around.\n    pub fn from_le_bytes<let N: u32>(bytes: [u8; N]) -> Field {\n        let mut v = 1;\n        let mut result = 0;\n\n        for i in 0..N {\n            result += (bytes[i] as Field) * v;\n            v = v * 256;\n        }\n        result\n    }\n\n    /// Convert a big endian byte array to a field element.\n    /// If the provided byte array overflows the field modulus then the Field will silently wrap around.\n    pub fn from_be_bytes<let N: u32>(bytes: [u8; N]) -> Field {\n        let mut v = 1;\n        let mut result = 0;\n\n        for i in 0..N {\n            result += (bytes[N-1-i] as Field) * v;\n            v = v * 256;\n        }\n        result\n    }\n}\n\n#[builtin(modulus_num_bits)]\npub comptime fn modulus_num_bits() -> u64 {}\n\n#[builtin(modulus_be_bits)]\npub comptime fn modulus_be_bits() -> [u1] {}\n\n#[builtin(modulus_le_bits)]\npub comptime fn modulus_le_bits() -> [u1] {}\n\n#[builtin(modulus_be_bytes)]\npub comptime fn modulus_be_bytes() -> [u8] {}\n\n#[builtin(modulus_le_bytes)]\npub comptime fn modulus_le_bytes() -> [u8] {}\n\n// Convert a 32 byte array to a field element by modding\npub fn bytes32_to_field(bytes32: [u8; 32]) -> Field {\n    // Convert it to a field element\n    let mut v = 1;\n    let mut high = 0 as Field;\n    let mut low = 0 as Field;\n\n    for i in 0..16 {\n        high = high + (bytes32[15 - i] as Field) * v;\n        low = low + (bytes32[16 + 15 - i] as Field) * v;\n        v = v * 256;\n    }\n    // Abuse that a % p + b % p = (a + b) % p and that low < p\n    low + high * v\n}\n\nfn lt_fallback(x: Field, y: Field) -> bool {\n    let x_bytes: [u8; 32] = x.to_le_bytes();\n    let y_bytes: [u8; 32] = y.to_le_bytes();\n    let mut x_is_lt = false;\n    let mut done = false;\n    for i in 0..32 {\n        if (!done) {\n            let x_byte = x_bytes[32 - 1 - i] as u8;\n            let y_byte = y_bytes[32 - 1 - i] as u8;\n            let bytes_match = x_byte == y_byte;\n            if !bytes_match {\n                x_is_lt = x_byte < y_byte;\n                done = true;\n            }\n        }\n    }\n    x_is_lt\n}\n\nmod tests {\n    #[test]\n    // docs:start:to_be_bits_example\n    fn test_to_be_bits() {\n        let field = 2;\n        let bits: [u1; 8] = field.to_be_bits();\n        assert_eq(bits, [0, 0, 0, 0, 0, 0, 1, 0]);\n    }\n    // docs:end:to_be_bits_example\n\n    #[test]\n    // docs:start:to_le_bits_example\n    fn test_to_le_bits() {\n        let field = 2;\n        let bits: [u1; 8] = field.to_le_bits();\n        assert_eq(bits, [0, 1, 0, 0, 0, 0, 0, 0]);\n    }\n    // docs:end:to_le_bits_example\n\n    #[test]\n    // docs:start:to_be_bytes_example\n    fn test_to_be_bytes() {\n        let field = 2;\n        let bits: [u8; 8] = field.to_be_bytes();\n        assert_eq(bits, [0, 0, 0, 0, 0, 0, 0, 2]);\n        assert_eq(Field::from_be_bytes::<8>(bits), field);\n    }\n    // docs:end:to_be_bytes_example\n\n    #[test]\n    // docs:start:to_le_bytes_example\n    fn test_to_le_bytes() {\n        let field = 2;\n        let bits: [u8; 8] = field.to_le_bytes();\n        assert_eq(bits, [2, 0, 0, 0, 0, 0, 0, 0]);\n        assert_eq(Field::from_le_bytes::<8>(bits), field);\n    }\n    // docs:end:to_le_bytes_example\n\n    #[test]\n    // docs:start:to_be_radix_example\n    fn test_to_be_radix() {\n        let field = 2;\n        let bits: [u8; 8] = field.to_be_radix(256);\n        assert_eq(bits, [0, 0, 0, 0, 0, 0, 0, 2]);\n        assert_eq(Field::from_be_bytes::<8>(bits), field);\n    }\n    // docs:end:to_be_radix_example\n\n    #[test]\n    // docs:start:to_le_radix_example\n    fn test_to_le_radix() {\n        let field = 2;\n        let bits: [u8; 8] = field.to_le_radix(256);\n        assert_eq(bits, [2, 0, 0, 0, 0, 0, 0, 0]);\n        assert_eq(Field::from_le_bytes::<8>(bits), field);\n    }\n    // docs:end:to_le_radix_example\n}\n","path":"std/field/mod.nr"},"29":{"source":"pub mod poseidon;\npub mod mimc;\npub mod poseidon2;\npub mod keccak;\npub mod sha256;\npub mod sha512;\n\nuse crate::default::Default;\nuse crate::uint128::U128;\nuse crate::collections::vec::Vec;\nuse crate::embedded_curve_ops::{EmbeddedCurvePoint, EmbeddedCurveScalar, multi_scalar_mul, multi_scalar_mul_slice};\nuse crate::meta::derive_via;\n\n// Kept for backwards compatibility\npub use sha256::{digest, sha256, sha256_compression, sha256_var};\n\n#[foreign(blake2s)]\n// docs:start:blake2s\npub fn blake2s<let N: u32>(input: [u8; N]) -> [u8; 32]\n// docs:end:blake2s\n{}\n\n#[foreign(blake3)]\n// docs:start:blake3\npub fn blake3<let N: u32>(input: [u8; N]) -> [u8; 32]\n// docs:end:blake3\n{}\n\n// docs:start:pedersen_commitment\npub fn pedersen_commitment<let N: u32>(input: [Field; N]) -> EmbeddedCurvePoint {\n    // docs:end:pedersen_commitment\n    pedersen_commitment_with_separator(input, 0)\n}\n\npub fn pedersen_hash_with_separator<let N: u32>(input: [Field; N], separator: u32) -> Field {\n    pedersen_hash_with_separator_noir(input, separator)\n}\n\npub fn pedersen_commitment_with_separator<let N: u32>(input: [Field; N], separator: u32) -> EmbeddedCurvePoint {\n    let value = __pedersen_commitment_with_separator(input, separator);\n    if (value[0] == 0) & (value[1] == 0) {\n        EmbeddedCurvePoint { x: 0, y: 0, is_infinite: true }\n    } else {\n        EmbeddedCurvePoint { x: value[0], y: value[1], is_infinite: false }\n    }\n}\n\n#[no_predicates]\nfn pedersen_commitment_with_separator_noir<let N: u32>(input: [Field; N], separator: u32) -> EmbeddedCurvePoint {\n    let mut points = [EmbeddedCurveScalar { lo: 0, hi: 0 }; N];\n    for i in 0..N {\n        // we use the unsafe version because the multi_scalar_mul will constrain the scalars.\n        points[i] = from_field_unsafe(input[i]);\n    }\n    let generators = derive_generators(\"DEFAULT_DOMAIN_SEPARATOR\".as_bytes(), separator);\n    multi_scalar_mul(generators, points)\n}\n\n#[no_predicates]\nfn pedersen_hash_with_separator_noir<let N: u32>(input: [Field; N], separator: u32) -> Field {\n    let mut scalars: Vec<EmbeddedCurveScalar> = Vec::from_slice([EmbeddedCurveScalar { lo: 0, hi: 0 }; N].as_slice()); //Vec::new();\n\n    for i in 0..N {\n        scalars.set(i, from_field_unsafe(input[i]));\n    }\n    scalars.push(EmbeddedCurveScalar { lo: N as Field, hi: 0 as Field });\n    let domain_generators :[EmbeddedCurvePoint; N]= derive_generators(\"DEFAULT_DOMAIN_SEPARATOR\".as_bytes(), separator);\n    let mut vec_generators = Vec::new();\n    for i in 0..N {\n        vec_generators.push(domain_generators[i]);\n    }\n    let length_generator : [EmbeddedCurvePoint; 1] = derive_generators(\"pedersen_hash_length\".as_bytes(), 0);\n    vec_generators.push(length_generator[0]);\n    multi_scalar_mul_slice(vec_generators.slice, scalars.slice)[0]\n}\n\n// docs:start:pedersen_hash\npub fn pedersen_hash<let N: u32>(input: [Field; N]) -> Field\n// docs:end:pedersen_hash\n{\n    pedersen_hash_with_separator_noir(input, 0)\n}\n\n#[foreign(pedersen_hash)]\nfn __pedersen_hash_with_separator<let N: u32>(input: [Field; N], separator: u32) -> Field {}\n\n#[foreign(pedersen_commitment)]\nfn __pedersen_commitment_with_separator<let N: u32>(input: [Field; N], separator: u32) -> [Field; 2] {}\n\n#[field(bn254)]\npub fn derive_generators<let N: u32, let M: u32>(domain_separator_bytes: [u8; M], starting_index: u32) -> [EmbeddedCurvePoint; N] {\n    crate::assert_constant(domain_separator_bytes);\n    // TODO(https://github.com/noir-lang/noir/issues/5672): Add back assert_constant on starting_index\n    __derive_generators(domain_separator_bytes, starting_index)\n}\n\n#[builtin(derive_pedersen_generators)]\n#[field(bn254)]\nfn __derive_generators<let N: u32, let M: u32>(domain_separator_bytes: [u8; M], starting_index: u32) -> [EmbeddedCurvePoint; N] {}\n\n#[field(bn254)]\n// Same as from_field but:\n// does not assert the limbs are 128 bits\n// does not assert the decomposition does not overflow the EmbeddedCurveScalar\nfn from_field_unsafe(scalar: Field) -> EmbeddedCurveScalar {\n    let (xlo, xhi) = unsafe {\n        crate::field::bn254::decompose_hint(scalar)\n    };\n    // Check that the decomposition is correct\n    assert_eq(scalar, xlo + crate::field::bn254::TWO_POW_128 * xhi);\n    EmbeddedCurveScalar { lo: xlo, hi: xhi }\n}\n\npub fn hash_to_field(inputs: [Field]) -> Field {\n    let mut sum = 0;\n\n    for input in inputs {\n        let input_bytes: [u8; 32] = input.to_le_bytes();\n        sum += crate::field::bytes32_to_field(blake2s(input_bytes));\n    }\n\n    sum\n}\n\n// docs:start:keccak256\npub fn keccak256<let N: u32>(input: [u8; N], message_size: u32) -> [u8; 32]\n// docs:end:keccak256\n{\n    crate::hash::keccak::keccak256(input, message_size)\n}\n\n#[foreign(poseidon2_permutation)]\npub fn poseidon2_permutation<let N: u32>(_input: [Field; N], _state_length: u32) -> [Field; N] {}\n\n// Generic hashing support.\n// Partially ported and impacted by rust.\n\n// Hash trait shall be implemented per type.\n#[derive_via(derive_hash)]\npub trait Hash {\n    fn hash<H>(self, state: &mut H) where H: Hasher;\n}\n\n// docs:start:derive_hash\ncomptime fn derive_hash(s: StructDefinition) -> Quoted {\n    let name = quote { Hash };\n    let signature = quote { fn hash<H>(_self: Self, _state: &mut H) where H: std::hash::Hasher };\n    let for_each_field = |name| quote { _self.$name.hash(_state); };\n    crate::meta::make_trait_impl(s, name, signature, for_each_field, quote {}, |fields| fields)\n}\n// docs:end:derive_hash\n\n// Hasher trait shall be implemented by algorithms to provide hash-agnostic means.\n// TODO: consider making the types generic here ([u8], [Field], etc.)\npub trait Hasher {\n    fn finish(self) -> Field;\n\n    fn write(&mut self, input: Field);\n}\n\n// BuildHasher is a factory trait, responsible for production of specific Hasher.\npub trait BuildHasher<H> where H: Hasher {\n    fn build_hasher(self) -> H;\n}\n\npub struct BuildHasherDefault<H>;\n\nimpl<H> BuildHasher<H> for BuildHasherDefault<H>\nwhere\n    H: Hasher + Default {\n    fn build_hasher(_self: Self) -> H {\n        H::default()\n    }\n}\n\nimpl<H> Default for BuildHasherDefault<H>\nwhere\n    H: Hasher + Default {\n    fn default() -> Self {\n        BuildHasherDefault {}\n    }\n}\n\nimpl Hash for Field {\n    fn hash<H>(self, state: &mut H) where H: Hasher {\n        H::write(state, self);\n    }\n}\n\nimpl Hash for u1 {\n    fn hash<H>(self, state: &mut H) where H: Hasher {\n        H::write(state, self as Field);\n    }\n}\n\nimpl Hash for u8 {\n    fn hash<H>(self, state: &mut H) where H: Hasher {\n        H::write(state, self as Field);\n    }\n}\n\nimpl Hash for u16 {\n    fn hash<H>(self, state: &mut H) where H: Hasher {\n        H::write(state, self as Field);\n    }\n}\n\nimpl Hash for u32 {\n    fn hash<H>(self, state: &mut H) where H: Hasher {\n        H::write(state, self as Field);\n    }\n}\n\nimpl Hash for u64 {\n    fn hash<H>(self, state: &mut H) where H: Hasher {\n        H::write(state, self as Field);\n    }\n}\n\nimpl Hash for i8 {\n    fn hash<H>(self, state: &mut H) where H: Hasher {\n        H::write(state, self as Field);\n    }\n}\n\nimpl Hash for i16 {\n    fn hash<H>(self, state: &mut H) where H: Hasher {\n        H::write(state, self as Field);\n    }\n}\n\nimpl Hash for i32 {\n    fn hash<H>(self, state: &mut H) where H: Hasher {\n        H::write(state, self as Field);\n    }\n}\n\nimpl Hash for i64 {\n    fn hash<H>(self, state: &mut H) where H: Hasher {\n        H::write(state, self as Field);\n    }\n}\n\nimpl Hash for bool {\n    fn hash<H>(self, state: &mut H) where H: Hasher {\n        H::write(state, self as Field);\n    }\n}\n\nimpl Hash for () {\n    fn hash<H>(_self: Self, _state: &mut H) where H: Hasher {}\n}\n\nimpl Hash for U128 {\n    fn hash<H>(self, state: &mut H) where H: Hasher {\n        H::write(state, self.lo as Field);\n        H::write(state, self.hi as Field);\n    }\n}\n\nimpl<T, let N: u32> Hash for [T; N] where T: Hash {\n    fn hash<H>(self, state: &mut H) where H: Hasher {\n        for elem in self {\n            elem.hash(state);\n        }\n    }\n}\n\nimpl<T> Hash for [T] where T: Hash {\n    fn hash<H>(self, state: &mut H) where H: Hasher {\n        self.len().hash(state);\n        for elem in self {\n            elem.hash(state);\n        }\n    }\n}\n\nimpl<A, B> Hash for (A, B) where A: Hash, B: Hash {\n    fn hash<H>(self, state: &mut H) where H: Hasher {\n        self.0.hash(state);\n        self.1.hash(state);\n    }\n}\n\nimpl<A, B, C> Hash for (A, B, C) where A: Hash, B: Hash, C: Hash {\n    fn hash<H>(self, state: &mut H) where H: Hasher {\n        self.0.hash(state);\n        self.1.hash(state);\n        self.2.hash(state);\n    }\n}\n\nimpl<A, B, C, D> Hash for (A, B, C, D) where A: Hash, B: Hash, C: Hash, D: Hash {\n    fn hash<H>(self, state: &mut H) where H: Hasher {\n        self.0.hash(state);\n        self.1.hash(state);\n        self.2.hash(state);\n        self.3.hash(state);\n    }\n}\n\nimpl<A, B, C, D, E> Hash for (A, B, C, D, E) where A: Hash, B: Hash, C: Hash, D: Hash, E: Hash {\n    fn hash<H>(self, state: &mut H) where H: Hasher {\n        self.0.hash(state);\n        self.1.hash(state);\n        self.2.hash(state);\n        self.3.hash(state);\n        self.4.hash(state);\n    }\n}\n\n// Some test vectors for Pedersen hash and Pedersen Commitment.\n// They have been generated using the same functions so the tests are for now useless\n// but they will be useful when we switch to Noir implementation.\n#[test]\nfn assert_pedersen() {\n    assert_eq(\n        pedersen_hash_with_separator([1], 1), 0x1b3f4b1a83092a13d8d1a59f7acb62aba15e7002f4440f2275edb99ebbc2305f\n    );\n    assert_eq(\n        pedersen_commitment_with_separator([1], 1), EmbeddedCurvePoint {\n        x: 0x054aa86a73cb8a34525e5bbed6e43ba1198e860f5f3950268f71df4591bde402,\n        y: 0x209dcfbf2cfb57f9f6046f44d71ac6faf87254afc7407c04eb621a6287cac126,\n        is_infinite: false\n    }\n    );\n\n    assert_eq(\n        pedersen_hash_with_separator([1, 2], 2), 0x26691c129448e9ace0c66d11f0a16d9014a9e8498ee78f4d69f0083168188255\n    );\n    assert_eq(\n        pedersen_commitment_with_separator([1, 2], 2), EmbeddedCurvePoint {\n        x: 0x2e2b3b191e49541fe468ec6877721d445dcaffe41728df0a0eafeb15e87b0753,\n        y: 0x2ff4482400ad3a6228be17a2af33e2bcdf41be04795f9782bd96efe7e24f8778,\n        is_infinite: false\n    }\n    );\n    assert_eq(\n        pedersen_hash_with_separator([1, 2, 3], 3), 0x0bc694b7a1f8d10d2d8987d07433f26bd616a2d351bc79a3c540d85b6206dbe4\n    );\n    assert_eq(\n        pedersen_commitment_with_separator([1, 2, 3], 3), EmbeddedCurvePoint {\n        x: 0x1fee4e8cf8d2f527caa2684236b07c4b1bad7342c01b0f75e9a877a71827dc85,\n        y: 0x2f9fedb9a090697ab69bf04c8bc15f7385b3e4b68c849c1536e5ae15ff138fd1,\n        is_infinite: false\n    }\n    );\n    assert_eq(\n        pedersen_hash_with_separator([1, 2, 3, 4], 4), 0xdae10fb32a8408521803905981a2b300d6a35e40e798743e9322b223a5eddc\n    );\n    assert_eq(\n        pedersen_commitment_with_separator([1, 2, 3, 4], 4), EmbeddedCurvePoint {\n        x: 0x07ae3e202811e1fca39c2d81eabe6f79183978e6f12be0d3b8eda095b79bdbc9,\n        y: 0x0afc6f892593db6fbba60f2da558517e279e0ae04f95758587760ba193145014,\n        is_infinite: false\n    }\n    );\n    assert_eq(\n        pedersen_hash_with_separator([1, 2, 3, 4, 5], 5), 0xfc375b062c4f4f0150f7100dfb8d9b72a6d28582dd9512390b0497cdad9c22\n    );\n    assert_eq(\n        pedersen_commitment_with_separator([1, 2, 3, 4, 5], 5), EmbeddedCurvePoint {\n        x: 0x1754b12bd475a6984a1094b5109eeca9838f4f81ac89c5f0a41dbce53189bb29,\n        y: 0x2da030e3cfcdc7ddad80eaf2599df6692cae0717d4e9f7bfbee8d073d5d278f7,\n        is_infinite: false\n    }\n    );\n    assert_eq(\n        pedersen_hash_with_separator([1, 2, 3, 4, 5, 6], 6), 0x1696ed13dc2730062a98ac9d8f9de0661bb98829c7582f699d0273b18c86a572\n    );\n    assert_eq(\n        pedersen_commitment_with_separator([1, 2, 3, 4, 5, 6], 6), EmbeddedCurvePoint {\n        x: 0x190f6c0e97ad83e1e28da22a98aae156da083c5a4100e929b77e750d3106a697,\n        y: 0x1f4b60f34ef91221a0b49756fa0705da93311a61af73d37a0c458877706616fb,\n        is_infinite: false\n    }\n    );\n    assert_eq(\n        pedersen_hash_with_separator([1, 2, 3, 4, 5, 6, 7], 7), 0x128c0ff144fc66b6cb60eeac8a38e23da52992fc427b92397a7dffd71c45ede3\n    );\n    assert_eq(\n        pedersen_commitment_with_separator([1, 2, 3, 4, 5, 6, 7], 7), EmbeddedCurvePoint {\n        x: 0x015441e9d29491b06563fac16fc76abf7a9534c715421d0de85d20dbe2965939,\n        y: 0x1d2575b0276f4e9087e6e07c2cb75aa1baafad127af4be5918ef8a2ef2fea8fc,\n        is_infinite: false\n    }\n    );\n    assert_eq(\n        pedersen_hash_with_separator([1, 2, 3, 4, 5, 6, 7, 8], 8), 0x2f960e117482044dfc99d12fece2ef6862fba9242be4846c7c9a3e854325a55c\n    );\n    assert_eq(\n        pedersen_commitment_with_separator([1, 2, 3, 4, 5, 6, 7, 8], 8), EmbeddedCurvePoint {\n        x: 0x1657737676968887fceb6dd516382ea13b3a2c557f509811cd86d5d1199bc443,\n        y: 0x1f39f0cb569040105fa1e2f156521e8b8e08261e635a2b210bdc94e8d6d65f77,\n        is_infinite: false\n    }\n    );\n    assert_eq(\n        pedersen_hash_with_separator([1, 2, 3, 4, 5, 6, 7, 8, 9], 9), 0x0c96db0790602dcb166cc4699e2d306c479a76926b81c2cb2aaa92d249ec7be7\n    );\n    assert_eq(\n        pedersen_commitment_with_separator([1, 2, 3, 4, 5, 6, 7, 8, 9], 9), EmbeddedCurvePoint {\n        x: 0x0a3ceae42d14914a432aa60ec7fded4af7dad7dd4acdbf2908452675ec67e06d,\n        y: 0xfc19761eaaf621ad4aec9a8b2e84a4eceffdba78f60f8b9391b0bd9345a2f2,\n        is_infinite: false\n    }\n    );\n    assert_eq(\n        pedersen_hash_with_separator([1, 2, 3, 4, 5, 6, 7, 8, 9, 10], 10), 0x2cd37505871bc460a62ea1e63c7fe51149df5d0801302cf1cbc48beb8dff7e94\n    );\n    assert_eq(\n        pedersen_commitment_with_separator([1, 2, 3, 4, 5, 6, 7, 8, 9, 10], 10), EmbeddedCurvePoint {\n        x: 0x2fb3f8b3d41ddde007c8c3c62550f9a9380ee546fcc639ffbb3fd30c8d8de30c,\n        y: 0x300783be23c446b11a4c0fabf6c91af148937cea15fcf5fb054abf7f752ee245,\n        is_infinite: false\n    }\n    );\n}\n","path":"std/hash/mod.nr"},"34":{"source":"use crate::hash::Hasher;\nuse crate::default::Default;\n\ncomptime global RATE: u32 = 3;\n\npub struct Poseidon2 {\n    cache: [Field;3],\n    state: [Field;4],\n    cache_size: u32,\n    squeeze_mode: bool, // 0 => absorb, 1 => squeeze\n}\n\nimpl Poseidon2 {\n    #[no_predicates]\n    pub fn hash<let N: u32>(input: [Field; N], message_size: u32) -> Field {\n        if message_size == N {\n            Poseidon2::hash_internal(input, N, false)\n        } else {\n            Poseidon2::hash_internal(input, message_size, true)\n        }\n    }\n\n    pub(crate) fn new(iv: Field) -> Poseidon2 {\n        let mut result = Poseidon2 { cache: [0; 3], state: [0; 4], cache_size: 0, squeeze_mode: false };\n        result.state[RATE] = iv;\n        result\n    }\n\n    fn perform_duplex(&mut self) {\n        // add the cache into sponge state\n        for i in 0..RATE {\n            // We effectively zero-pad the cache by only adding to the state\n            // cache that is less than the specified `cache_size`\n            if i < self.cache_size {\n                self.state[i] += self.cache[i];\n            }\n        }\n        self.state = crate::hash::poseidon2_permutation(self.state, 4);\n    }\n\n    fn absorb(&mut self, input: Field) {\n        assert(!self.squeeze_mode);\n        if self.cache_size == RATE {\n            // If we're absorbing, and the cache is full, apply the sponge permutation to compress the cache\n            self.perform_duplex();\n            self.cache[0] = input;\n            self.cache_size = 1;\n        } else {\n            // If we're absorbing, and the cache is not full, add the input into the cache\n            self.cache[self.cache_size] = input;\n            self.cache_size += 1;\n        }\n    }\n\n    fn squeeze(&mut self) -> Field {\n        assert(!self.squeeze_mode);\n        // If we're in absorb mode, apply sponge permutation to compress the cache.\n        self.perform_duplex();\n        self.squeeze_mode = true;\n\n        // Pop one item off the top of the permutation and return it.\n        self.state[0]\n    }\n\n    fn hash_internal<let N: u32>(input: [Field; N], in_len: u32, is_variable_length: bool) -> Field {\n        let two_pow_64 = 18446744073709551616;\n        let iv : Field = (in_len as Field) * two_pow_64;\n        let mut sponge = Poseidon2::new(iv);\n        for i in 0..input.len() {\n            if i < in_len {\n                sponge.absorb(input[i]);\n            }\n        }\n\n        // In the case where the hash preimage is variable-length, we append `1` to the end of the input, to distinguish\n        // from fixed-length hashes. (the combination of this additional field element + the hash IV ensures\n        // fixed-length and variable-length hashes do not collide)\n        if is_variable_length {\n            sponge.absorb(1);\n        }\n        sponge.squeeze()\n    }\n}\n\npub struct Poseidon2Hasher{\n    _state: [Field],\n}\n\nimpl Hasher for Poseidon2Hasher {\n    fn finish(self) -> Field {\n        let iv : Field = (self._state.len() as Field) * 18446744073709551616; // iv = (self._state.len() << 64)\n        let mut sponge = Poseidon2::new(iv);\n        for i in 0..self._state.len() {\n            sponge.absorb(self._state[i]);\n        }\n        sponge.squeeze()\n    }\n\n    fn write(&mut self, input: Field) {\n        self._state = self._state.push_back(input);\n    }\n}\n\nimpl Default for Poseidon2Hasher {\n    fn default() -> Self {\n        Poseidon2Hasher { _state: &[] }\n    }\n}\n","path":"std/hash/poseidon2.nr"},"70":{"source":"// use dep::protocol_types::{\n//     abis::{\n//         call_context::CallContext, function_selector::FunctionSelector, max_block_number::MaxBlockNumber,\n//         validation_requests::{KeyValidationRequest, KeyValidationRequestAndGenerator},\n//         private_call_request::PrivateCallRequest, private_circuit_public_inputs::PrivateCircuitPublicInputs,\n//         public_call_request::PublicCallRequest, read_request::ReadRequest, note_hash::NoteHash,\n//         nullifier::Nullifier, log_hash::{LogHash, NoteLogHash, EncryptedLogHash}\n//     },\n//     address::{AztecAddress, EthAddress},\n//     constants::{\n//         MAX_NOTE_HASHES_PER_CALL, MAX_L2_TO_L1_MSGS_PER_CALL, MAX_NULLIFIERS_PER_CALL,\n//         MAX_PRIVATE_CALL_STACK_LENGTH_PER_CALL, MAX_PUBLIC_CALL_STACK_LENGTH_PER_CALL,\n//         MAX_NOTE_HASH_READ_REQUESTS_PER_CALL, MAX_NULLIFIER_READ_REQUESTS_PER_CALL,\n//         MAX_KEY_VALIDATION_REQUESTS_PER_CALL, MAX_ENCRYPTED_LOGS_PER_CALL, MAX_UNENCRYPTED_LOGS_PER_CALL,\n//         MAX_NOTE_ENCRYPTED_LOGS_PER_CALL, PUBLIC_DISPATCH_SELECTOR\n//     },\n//     header::Header, messaging::l2_to_l1_message::L2ToL1Message, traits::Empty\n// };\nuse dep::protocol_types::{\n    header::{Header, HEADER_LENGTH}, address::{AztecAddress},\n    utils::{arr_copy_slice, field::{full_field_less_than, full_field_greater_than}},\n    merkle_tree::root::root_from_sibling_path,\n    constants::{\n        GENERATOR_INDEX__NOTE_NULLIFIER,\n        GENERATOR_INDEX__SECRET_HASH // ?\n    },\n    hash::poseidon2_hash_with_separator\n};\nuse dep::value_note::value_note::ValueNote;\nuse dep::nft_contract::types::nft_note::NFTNote;\nuse aztec::{\n    note::{\n        utils::compute_note_hash_for_nullify,\n        note_header::NoteHeader,\n    },\n    oracle::{\n        get_membership_witness::MembershipWitness,\n        get_nullifier_membership_witness::{\n            NullifierMembershipWitness,\n            NULLIFIER_MEMBERSHIP_WITNESS // 24\n        }\n    },\n};\nuse std::embedded_curve_ops::fixed_base_scalar_mul as derive_public_key;\nuse protocol_types::scalar::Scalar;\n\nfn main(\n    blockheader_serd: pub [Field; 24],\n    // TODO I guess it's possible to invent a context when sharing `nsk_m` is ok; though it will be narrow\n    nsk_m: [Field; 2],\n    // TODO should hash of the nullifier key be private?\n    note_content: [Field; 3],\n    contract_address_as_field: pub Field,\n    nonce: Field,\n    // TODO is it possible to leverage this further?\n    storage_slot: Field,\n    witness_membership_serd: [Field; 33],\n    low_nullifier_membership_witness_serd: [Field; NULLIFIER_MEMBERSHIP_WITNESS],\n    debug_notehash: Field,\n    debug_nsk_app: Field\n) {\n    let contract_address = AztecAddress::from_field(contract_address_as_field);\n\n    let mut note_the = \n        // ValueNote::\n        NFTNote::\n            deserialize_content(note_content);\n    note_the.set_header(NoteHeader::new(\n        contract_address,\n        nonce,\n        storage_slot\n    ));\n    let nsk_m = Scalar::new(nsk_m[0], nsk_m[1]);\n    assert_eq(\n        note_content[1], \n        derive_public_key(nsk_m).hash(),\n        \"wrong nullifier key\"\n    );\n    // Header::deserialize(blockheader).prove_note_inclusion(note_the);\n    // let witness_membership = MembershipWitness { \n    //     index: witness_membership_serd[0], path: arr_copy_slice(\n    //         witness_membership_serd, [0; 32], 1\n    //     ) \n    // };\n\n    let blockheader = Header::deserialize(blockheader_serd);\n    let note_hashed_for_nullify = compute_note_hash_for_nullify(note_the);\n\n    assert_eq(note_hashed_for_nullify, debug_notehash, \"wrong note hashing\");\n    \n    assert_eq(\n        // TODO optimize by leaving only a root in the data exchange\n        blockheader.state.partial.note_hash_tree.root, \n        root_from_sibling_path(\n            note_hashed_for_nullify, \n            witness_membership_serd[0], \n            arr_copy_slice(\n                witness_membership_serd, [0; 32], 1\n            ) \n        ), \n        \"Proving note inclusion failed\"\n    );\n\n    assert_eq(debug_nsk_app, poseidon2_hash_with_separator(\n        [nsk_m.hi, nsk_m.lo, contract_address_as_field],\n        48\n    ), \"bad `nsk_app` algorithm\");\n\n    let nullifier = poseidon2_hash_with_separator(\n        [\n            note_hashed_for_nullify,\n            poseidon2_hash_with_separator(\n                [nsk_m.hi, nsk_m.lo, contract_address_as_field],\n                48\n            )\n        ], \n        GENERATOR_INDEX__NOTE_NULLIFIER as Field\n    );\n    // pasta of `prove_nullifier_non_inclusion` from </home/serge/nargo/github.com/AztecProtocol/aztec-packages/aztec-packages-v0.57.0/noir-projects/aztec-nr/aztec/src/history/nullifier_non_inclusion.nr>\n    let witness = NullifierMembershipWitness::deserialize(low_nullifier_membership_witness_serd);\n    let low_nullifier_leaf = witness.leaf_preimage;\n    assert_eq(\n        blockheader.state.partial.nullifier_tree.root,\n        root_from_sibling_path(\n            low_nullifier_leaf.hash(), \n            witness.index, witness.path\n        ), \n        \"Proving nullifier non-inclusion failed: Could not prove low nullifier inclusion\"\n    );\n    assert(\n        full_field_less_than(low_nullifier_leaf.nullifier, nullifier), \"Proving nullifier non-inclusion failed: low_nullifier.value < nullifier.value check failed\"\n    );\n    assert( \n        full_field_greater_than(low_nullifier_leaf.next_nullifier, nullifier)\n        | (low_nullifier_leaf.next_index == 0), \"Proving nullifier non-inclusion failed: low_nullifier.next_value > nullifier.value check failed\"\n    );\n}\n","path":"/home/serge/Desktop/noir_part/src/main.nr"},"154":{"source":"use dep::protocol_types::{\n    abis::nullifier_leaf_preimage::{NullifierLeafPreimage, NULLIFIER_LEAF_PREIMAGE_LENGTH},\n    constants::NULLIFIER_TREE_HEIGHT, utils::arr_copy_slice\n};\n\n// INDEX_LENGTH + NULLIFIER_LEAF_PREIMAGE_LENGTH + NULLIFIER_TREE_HEIGHT\nglobal NULLIFIER_MEMBERSHIP_WITNESS: u32 = 24;\n\npub struct NullifierMembershipWitness {\n    index: Field,\n    leaf_preimage: NullifierLeafPreimage,\n    path: [Field; NULLIFIER_TREE_HEIGHT],\n}\n\nimpl NullifierMembershipWitness {\n    pub fn deserialize(fields: [Field; NULLIFIER_MEMBERSHIP_WITNESS]) -> Self {\n        let leaf_preimage_fields = arr_copy_slice(fields, [0; NULLIFIER_LEAF_PREIMAGE_LENGTH], 1);\n        Self {\n            index: fields[0],\n            leaf_preimage: NullifierLeafPreimage::deserialize(leaf_preimage_fields),\n            path: arr_copy_slice(\n                fields,\n                [0; NULLIFIER_TREE_HEIGHT],\n                1 + NULLIFIER_LEAF_PREIMAGE_LENGTH\n            )\n        }\n    }\n}\n\n#[oracle(getLowNullifierMembershipWitness)]\nunconstrained fn get_low_nullifier_membership_witness_oracle(\n    _block_number: u32,\n    _nullifier: Field\n) -> [Field; NULLIFIER_MEMBERSHIP_WITNESS] {}\n\n// Nullifier here refers to the nullifier we are looking to get non-inclusion proof for (by proving that a lower\n// nullifier's next_value is bigger than the nullifier)\nunconstrained pub fn get_low_nullifier_membership_witness(block_number: u32, nullifier: Field) -> NullifierMembershipWitness {\n    let fields = get_low_nullifier_membership_witness_oracle(block_number, nullifier);\n    NullifierMembershipWitness::deserialize(fields)\n}\n\n#[oracle(getNullifierMembershipWitness)]\nunconstrained fn get_nullifier_membership_witness_oracle(\n    _block_number: u32,\n    _nullifier: Field\n) -> [Field; NULLIFIER_MEMBERSHIP_WITNESS] {}\n\n// Nullifier here refers to the nullifier we are looking to get non-inclusion proof for (by proving that a lower\n// nullifier's next_value is bigger than the nullifier)\nunconstrained pub fn get_nullifier_membership_witness(block_number: u32, nullifier: Field) -> NullifierMembershipWitness {\n    let fields = get_nullifier_membership_witness_oracle(block_number, nullifier);\n    NullifierMembershipWitness::deserialize(fields)\n}\n","path":"/home/serge/nargo/github.com/AztecProtocol/aztec-packages/aztec-packages-v0.57.0/noir-projects/aztec-nr/aztec/src/oracle/get_nullifier_membership_witness.nr"},"165":{"source":"use crate::{\n    context::PrivateContext,\n    note::{note_header::NoteHeader, note_interface::{NullifiableNote, NoteInterface}}\n};\n\nuse dep::protocol_types::{\n    hash::{\n    compute_unique_note_hash, compute_siloed_note_hash as compute_siloed_note_hash,\n    compute_siloed_nullifier as compute_siloed_nullifier_from_preimage\n},\n    utils::arr_copy_slice\n};\n\npub fn compute_siloed_nullifier<Note, let N: u32>(\n    note_with_header: Note,\n    context: &mut PrivateContext\n) -> Field where Note: NoteInterface<N> + NullifiableNote {\n    let header = note_with_header.get_header();\n    let note_hash_for_nullify = compute_note_hash_for_nullify(note_with_header);\n    let inner_nullifier = note_with_header.compute_nullifier(context, note_hash_for_nullify);\n\n    compute_siloed_nullifier_from_preimage(header.contract_address, inner_nullifier)\n}\n\n// TODO(#7775): make this not impossible to understand\npub fn compute_note_hash_for_read_request<Note, let N: u32>(note: Note) -> Field where Note: NoteInterface<N> + NullifiableNote {\n    let note_hash = note.compute_note_hash();\n    let nonce = note.get_header().nonce;\n    let counter = note.get_header().note_hash_counter;\n\n    if counter != 0 {\n        note_hash\n    } else {\n        compute_unique_note_hash(nonce, note_hash)\n    }\n}\n\n// TODO(#7775): make this not impossible to understand\npub fn compute_note_hash_for_nullify_internal<Note, let N: u32>(\n    note: Note,\n    note_hash_for_read_request: Field\n) -> Field where Note: NoteInterface<N> + NullifiableNote {\n    let header = note.get_header();\n\n    if header.note_hash_counter != 0 {\n        if header.nonce == 0 {\n            // Case 1: Transient note\n            note_hash_for_read_request\n        } else {\n            // Case 2: Non-revertible note, nullified by a revertible nullifier\n            let unique_note_hash = compute_unique_note_hash(header.nonce, note_hash_for_read_request);\n            compute_siloed_note_hash(header.contract_address, unique_note_hash)\n        }\n    } else {\n        // Case 3: Note from a previous transaction\n        // note_hash_for_read_request is already the unique_note_hash in this case\n        compute_siloed_note_hash(header.contract_address, note_hash_for_read_request)\n    }\n}\n\n// TODO(#7775): nuke this commented out code - kept it around as it contains comments which might be helpful when tackling #7775\n// pub fn compute_note_hash_for_nullify<Note, let N: u32, let M: u32>(note: Note) -> Field where Note: NoteInterface<N> {\n//     let header = note.get_header();\n//     // There are 3 cases for reading a note intended for consumption:\n//     // 1. The note was inserted in this transaction, is revertible, or is not nullified by a revertible nullifier in\n//     //    the same transaction: (note_hash_counter != 0) & (nonce == 0)\n//     // 2. The note was inserted in this transaction, is non-revertible, and is nullified by a revertible nullifier in\n//     //    the same transaction: (note_hash_counter != 0) & (nonce != 0)\n//     // 3. The note was inserted in a previous transaction: (note_hash_counter == 0) & (nonce != 0)\n\n//     let note_hash = note.compute_note_hiding_point().x;\n\n//     if header.nonce == 0 {\n//         // Case 1.\n//         // If a note is transient, we just read the note_hash (kernel will hash it with nonce and silo by contract address).\n//         note_hash\n//     } else {\n//         // Case 2: If a note is non-revertible, and is nullified by a revertible nullifier, we cannot squash them in the\n//         // private reset circuit. Because if the tx reverts, we will have to keep the note hash and throw away the\n//         // nullifier.\n//         // And if the tx does not revert, both will be emitted. In which case, the nullifier must be created in the app\n//         // from the siloed note hash.\n//         // The kernel circuit will check that a nullifier with non-zero note_nonce is linked to a note hash, whose\n//         // siloed note hash matches the note hash specified in the nullifier.\n\n//         // Case 3: If a note is not from the current transaction, that means we are reading a settled note (from\n//         // tree) created in a previous TX. So we need the siloed_note_hash which has already been hashed with\n//         // nonce and then contract address. This hash will match the existing leaf in the note hash\n//         // tree, so the kernel can just perform a membership check directly on this hash/leaf.\n//         let unique_note_hash = compute_unique_note_hash(header.nonce, note_hash);\n//         compute_siloed_note_hash(header.contract_address, unique_note_hash)\n//         // IMPORTANT NOTE ON REDUNDANT SILOING BY CONTRACT ADDRESS: The note hash computed above is\n//         // \"siloed\" by contract address. When a note hash is computed solely for the purpose of\n//         // nullification, it is not strictly necessary to silo the note hash before computing\n//         // its nullifier. In other words, it is NOT NECESSARY for protocol security that a nullifier\n//         // be computed from a siloed note hash. After all, persistable note hashes and nullifiers are\n//         // siloed by the kernel circuit. That being said, the siloed note hash computed above CAN be\n//         // used for nullifier computation, and this achieves the (arguably unnecessary) property that\n//         // nullifiers are computed from a note hash's fully-computed note hash tree leaf.\n//     }\n// }\n\npub fn compute_note_hash_for_nullify<Note, let N: u32>(note: Note) -> Field where Note: NoteInterface<N> + NullifiableNote {\n    let note_hash_for_read_request = compute_note_hash_for_read_request(note);\n    compute_note_hash_for_nullify_internal(note, note_hash_for_read_request)\n}\n\nunconstrained pub fn compute_note_hash_and_optionally_a_nullifier<T, let N: u32, let S: u32>(\n    deserialize_content: fn([Field; N]) -> T,\n    note_header: NoteHeader,\n    compute_nullifier: bool,\n    serialized_note: [Field; S]\n) -> [Field; 4] where T: NoteInterface<N> + NullifiableNote {\n    let mut note = deserialize_content(arr_copy_slice(serialized_note, [0; N], 0));\n    note.set_header(note_header);\n\n    let note_hash = note.compute_note_hash();\n    let unique_note_hash = compute_unique_note_hash(note_header.nonce, note_hash);\n    let siloed_note_hash = compute_siloed_note_hash(note_header.contract_address, unique_note_hash);\n\n    let inner_nullifier = if compute_nullifier {\n        note.compute_nullifier_without_context()\n    } else {\n        0\n    };\n    // docs:start:compute_note_hash_and_optionally_a_nullifier_returns\n    [note_hash, unique_note_hash, siloed_note_hash, inner_nullifier]\n    // docs:end:compute_note_hash_and_optionally_a_nullifier_returns\n}\n","path":"/home/serge/nargo/github.com/AztecProtocol/aztec-packages/aztec-packages-v0.57.0/noir-projects/aztec-nr/aztec/src/note/utils.nr"},"192":{"source":"use crate::{hash::merkle_hash, merkle_tree::merkle_tree::MerkleTree};\n\n// Calculate the Merkle tree root from the sibling path and leaf.\n//\n// The leaf is hashed with its sibling, and then the result is hashed\n// with the next sibling etc in the path. The last hash is the root.\n//\n// TODO(David/Someone): The cpp code is using a uint256, whereas its\n// TODO a bit simpler in Noir to just have a bit array.\n// TODO: I'd generally like to avoid u256 for algorithms like\n// this because it means we never even need to consider cases where\n// the index is greater than p.\npub fn root_from_sibling_path<let N: u32>(\n    leaf: Field,\n    leaf_index: Field,\n    sibling_path: [Field; N]\n) -> Field {\n    let mut node = leaf;\n    let indices: [u1; N] = leaf_index.to_le_bits();\n\n    for i in 0..N {\n        let (hash_left, hash_right) = if indices[i] == 1 {\n            (sibling_path[i], node)\n        } else {\n            (node, sibling_path[i])\n        };\n        node = merkle_hash(hash_left, hash_right);\n    }\n    node\n}\n\npub fn calculate_subtree_root<let N: u32>(leaves: [Field; N]) -> Field {\n    MerkleTree::new(leaves).get_root()\n}\n\n// These values are precomputed and we run tests to ensure that they\n// are correct. The values themselves were computed from the cpp code.\n//\n// Would be good if we could use width since the compute_subtree\n// algorithm uses depth.\npub fn calculate_empty_tree_root(depth: u32) -> Field {\n    if depth == 0 {\n        0\n    } else if depth == 1 {\n        0x0b63a53787021a4a962a452c2921b3663aff1ffd8d5510540f8e659e782956f1\n    } else if depth == 2 {\n        0x0e34ac2c09f45a503d2908bcb12f1cbae5fa4065759c88d501c097506a8b2290\n    } else if depth == 3 {\n        0x21f9172d72fdcdafc312eee05cf5092980dda821da5b760a9fb8dbdf607c8a20\n    } else if depth == 4 {\n        0x2373ea368857ec7af97e7b470d705848e2bf93ed7bef142a490f2119bcf82d8e\n    } else if depth == 5 {\n        0x120157cfaaa49ce3da30f8b47879114977c24b266d58b0ac18b325d878aafddf\n    } else if depth == 6 {\n        0x01c28fe1059ae0237b72334700697bdf465e03df03986fe05200cadeda66bd76\n    } else if depth == 7 {\n        0x2d78ed82f93b61ba718b17c2dfe5b52375b4d37cbbed6f1fc98b47614b0cf21b\n    } else if depth == 8 {\n        0x067243231eddf4222f3911defbba7705aff06ed45960b27f6f91319196ef97e1\n    } else if depth == 9 {\n        0x1849b85f3c693693e732dfc4577217acc18295193bede09ce8b97ad910310972\n    } else if depth == 10 {\n        0x2a775ea761d20435b31fa2c33ff07663e24542ffb9e7b293dfce3042eb104686\n    } else {\n        panic(f\"depth should be between 0 and 10\")\n    }\n}\n\n#[test]\nfn test_merkle_root_interop_test() {\n    // This is a test to ensure that we match the cpp implementation.\n    // You can grep for `TEST_F(root_rollup_tests, noir_interop_test)`\n    // to find the test that matches this.\n    let root = calculate_subtree_root([1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4]);\n    assert(0x1a09d935ae110b4c861fcec8f9099ec30b4485022aeb3d3cf9d7168e38fdc231 == root);\n\n    let empty_root = calculate_subtree_root([0; 16]);\n    assert(0x2373ea368857ec7af97e7b470d705848e2bf93ed7bef142a490f2119bcf82d8e == empty_root);\n}\n\n#[test]\nfn test_empty_subroot() {\n    assert(calculate_empty_tree_root(0) == 0);\n\n    let expected_empty_root_2 = calculate_subtree_root([0; 2]);\n    assert(calculate_empty_tree_root(1) == expected_empty_root_2);\n\n    let expected_empty_root_4 = calculate_subtree_root([0; 4]);\n    assert(calculate_empty_tree_root(2) == expected_empty_root_4);\n\n    let expected_empty_root_8 = calculate_subtree_root([0; 8]);\n    assert(calculate_empty_tree_root(3) == expected_empty_root_8);\n\n    let expected_empty_root_16 = calculate_subtree_root([0; 16]);\n    assert(calculate_empty_tree_root(4) == expected_empty_root_16);\n\n    let expected_empty_root_32 = calculate_subtree_root([0; 32]);\n    assert(calculate_empty_tree_root(5) == expected_empty_root_32);\n\n    let expected_empty_root_64 = calculate_subtree_root([0; 64]);\n    assert(calculate_empty_tree_root(6) == expected_empty_root_64);\n\n    let expected_empty_root_128 = calculate_subtree_root([0; 128]);\n    assert(calculate_empty_tree_root(7) == expected_empty_root_128);\n\n    let expected_empty_root_256 = calculate_subtree_root([0; 256]);\n    assert(calculate_empty_tree_root(8) == expected_empty_root_256);\n\n    let expected_empty_root_512 = calculate_subtree_root([0; 512]);\n    assert(calculate_empty_tree_root(9) == expected_empty_root_512);\n\n    let expected_empty_root_1024 = calculate_subtree_root([0; 1024]);\n    assert(calculate_empty_tree_root(10) == expected_empty_root_1024);\n}\n","path":"/home/serge/nargo/github.com/AztecProtocol/aztec-packages/aztec-packages-v0.57.0/noir-projects/noir-protocol-circuits/crates/types/src/merkle_tree/root.nr"},"211":{"source":"use crate::{\n    abis::{\n    contract_class_function_leaf_preimage::ContractClassFunctionLeafPreimage,\n    function_selector::FunctionSelector, log_hash::{LogHash, ScopedLogHash, ScopedEncryptedLogHash},\n    note_hash::ScopedNoteHash, nullifier::ScopedNullifier\n},\n    address::{AztecAddress, EthAddress},\n    constants::{\n    FUNCTION_TREE_HEIGHT, GENERATOR_INDEX__SILOED_NOTE_HASH, GENERATOR_INDEX__OUTER_NULLIFIER,\n    GENERATOR_INDEX__VK, GENERATOR_INDEX__NOTE_HASH_NONCE, GENERATOR_INDEX__UNIQUE_NOTE_HASH,\n    MAX_ENCRYPTED_LOGS_PER_TX, MAX_NOTE_ENCRYPTED_LOGS_PER_TX\n},\n    merkle_tree::root::root_from_sibling_path,\n    messaging::l2_to_l1_message::{L2ToL1Message, ScopedL2ToL1Message},\n    recursion::verification_key::VerificationKey, traits::{is_empty, ToField},\n    utils::field::field_from_bytes_32_trunc\n};\nuse super::utils::field::field_from_bytes;\n\npub fn sha256_to_field<let N: u32>(bytes_to_hash: [u8; N]) -> Field {\n    let sha256_hashed = std::hash::sha256(bytes_to_hash);\n    let hash_in_a_field = field_from_bytes_32_trunc(sha256_hashed);\n\n    hash_in_a_field\n}\n\npub fn private_functions_root_from_siblings(\n    selector: FunctionSelector,\n    vk_hash: Field,\n    function_leaf_index: Field,\n    function_leaf_sibling_path: [Field; FUNCTION_TREE_HEIGHT]\n) -> Field {\n    let function_leaf_preimage = ContractClassFunctionLeafPreimage { selector, vk_hash };\n    let function_leaf = function_leaf_preimage.hash();\n    root_from_sibling_path(function_leaf, function_leaf_index, function_leaf_sibling_path)\n}\n\nfn compute_note_hash_nonce(tx_hash: Field, note_index_in_tx: u32) -> Field {\n    // Hashing tx hash with note index in tx is guaranteed to be unique\n    poseidon2_hash_with_separator(\n        [\n        tx_hash,\n        note_index_in_tx as Field\n    ],\n        GENERATOR_INDEX__NOTE_HASH_NONCE\n    )\n}\n\npub fn compute_unique_note_hash(nonce: Field, note_hash: Field) -> Field {\n    let inputs = [nonce, note_hash];\n    poseidon2_hash_with_separator(inputs, GENERATOR_INDEX__UNIQUE_NOTE_HASH)\n}\n\npub fn compute_siloed_note_hash(app: AztecAddress, unique_note_hash: Field) -> Field {\n    poseidon2_hash_with_separator(\n        [\n        app.to_field(),\n        unique_note_hash\n    ],\n        GENERATOR_INDEX__SILOED_NOTE_HASH\n    )\n}\n\n/// Siloing in the context of Aztec refers to the process of hashing a note hash with a contract address (this way\n/// the note hash is scoped to a specific contract). This is used to prevent intermingling of notes between contracts.\npub fn silo_note_hash(note_hash: ScopedNoteHash, tx_hash: Field, note_index_in_tx: u32) -> Field {\n    if note_hash.contract_address.is_zero() {\n        0\n    } else {\n        let nonce = compute_note_hash_nonce(tx_hash, note_index_in_tx);\n        let unique_note_hash = compute_unique_note_hash(nonce, note_hash.value());\n        compute_siloed_note_hash(note_hash.contract_address, unique_note_hash)\n    }\n}\n\npub fn compute_siloed_nullifier(app: AztecAddress, nullifier: Field) -> Field {\n    poseidon2_hash_with_separator(\n        [\n        app.to_field(),\n        nullifier\n    ],\n        GENERATOR_INDEX__OUTER_NULLIFIER\n    )\n}\n\npub fn silo_nullifier(nullifier: ScopedNullifier) -> Field {\n    if nullifier.contract_address.is_zero() {\n        nullifier.value() // Return value instead of 0 because the first nullifier's contract address is zero.\n    } else {\n        compute_siloed_nullifier(nullifier.contract_address, nullifier.value())\n    }\n}\n\npub fn silo_encrypted_log_hash(log_hash: ScopedLogHash) -> Field {\n    // We assume contract address has already been masked\n    if log_hash.contract_address.is_zero() {\n        0\n    } else {\n        accumulate_sha256([log_hash.contract_address.to_field(), log_hash.log_hash.value])\n    }\n}\n\npub fn mask_encrypted_log_hash(scoped_log: ScopedEncryptedLogHash) -> AztecAddress {\n    if scoped_log.contract_address.is_zero() {\n        AztecAddress::from_field(0)\n    } else if (scoped_log.log_hash.randomness == 0) {\n        scoped_log.contract_address\n    } else {\n        AztecAddress::from_field(\n            poseidon2_hash_with_separator(\n                [scoped_log.contract_address.to_field(), scoped_log.log_hash.randomness],\n                0\n            )\n        )\n    }\n}\n\nfn compute_siloed_unencrypted_log_hash(address: AztecAddress, log_hash: Field) -> Field {\n    accumulate_sha256([address.to_field(), log_hash])\n}\n\npub fn silo_unencrypted_log_hash(log_hash: ScopedLogHash) -> Field {\n    if log_hash.contract_address.is_zero() {\n        0\n    } else {\n        compute_siloed_unencrypted_log_hash(log_hash.contract_address, log_hash.value())\n    }\n}\n\npub fn merkle_hash(left: Field, right: Field) -> Field {\n    poseidon2_hash([left, right])\n}\n\npub fn stdlib_recursion_verification_key_compress_native_vk(_vk: VerificationKey) -> Field {\n    // Original cpp code\n    // stdlib::recursion::verification_key<CT::bn254>::compress_native(private_call.vk, GeneratorIndex::VK);\n    // The above cpp method is only ever called on verification key, so it has been special cased here\n    let _hash_index = GENERATOR_INDEX__VK;\n    0\n}\n\npub fn compute_l2_to_l1_hash(\n    contract_address: AztecAddress,\n    recipient: EthAddress,\n    content: Field,\n    rollup_version_id: Field,\n    chain_id: Field\n) -> Field {\n    let mut bytes: BoundedVec<u8, 160> = BoundedVec::new();\n\n    let inputs = [contract_address.to_field(), rollup_version_id, recipient.to_field(), chain_id, content];\n    for i in 0..inputs.len() {\n        // TODO are bytes be in fr.to_buffer() ?\n        let item_bytes: [u8; 32] = inputs[i].to_be_bytes();\n        for j in 0..32 {\n            bytes.push(item_bytes[j]);\n        }\n    }\n\n    sha256_to_field(bytes.storage)\n}\n\npub fn silo_l2_to_l1_message(msg: ScopedL2ToL1Message, rollup_version_id: Field, chain_id: Field) -> Field {\n    if msg.contract_address.is_zero() {\n        0\n    } else {\n        compute_l2_to_l1_hash(\n            msg.contract_address,\n            msg.message.recipient,\n            msg.message.content,\n            rollup_version_id,\n            chain_id\n        )\n    }\n}\n\n// Computes sha256 hash of 2 input hashes.\n//\n// NB: This method now takes in two 31 byte fields - it assumes that any input\n// is the result of a sha_to_field hash and => is truncated\n//\n// TODO(Jan and David): This is used for the encrypted_log hashes.\n// Can we check to see if we can just use hash_to_field or pedersen_compress here?\n//\npub fn accumulate_sha256(input: [Field; 2]) -> Field {\n    // This is a note about the cpp code, since it takes an array of Fields\n    // instead of a U128.\n    // 4 Field elements when converted to bytes will usually\n    // occupy 4 * 32 = 128 bytes.\n    // However, this function is making the assumption that each Field\n    // only occupies 128 bits.\n    //\n    // TODO(David): This does not seem to be getting guaranteed anywhere in the code?\n\n    // Concatentate two fields into 32x2 = 64 bytes\n    // accumulate_sha256 assumes that the inputs are pre-truncated 31 byte numbers\n    let mut hash_input_flattened = [0; 64];\n    for offset in 0..input.len() {\n        let input_as_bytes: [u8; 32] = input[offset].to_be_bytes();\n        for byte_index in 0..32 {\n            hash_input_flattened[offset * 32 + byte_index] = input_as_bytes[byte_index];\n        }\n    }\n\n    sha256_to_field(hash_input_flattened)\n}\n\n// Computes the final logs hash for a tx.\n// NB: this assumes MAX_ENCRYPTED_LOGS_PER_TX == MAX_UNENCRYPTED_LOGS_PER_TX\n// to avoid doubling code, since we can't define the byte len to be 32*N directly.\npub fn compute_tx_logs_hash(logs: [LogHash; MAX_ENCRYPTED_LOGS_PER_TX]) -> Field {\n    // Convert each field element into a byte array and append the bytes to `hash_input_flattened`\n    let mut hash_input_flattened = [0; MAX_ENCRYPTED_LOGS_PER_TX * 32];\n    for offset in 0..MAX_ENCRYPTED_LOGS_PER_TX {\n        let input_as_bytes: [u8; 32] = logs[offset].value.to_be_bytes();\n        for byte_index in 0..32 {\n            hash_input_flattened[offset * 32 + byte_index] = input_as_bytes[byte_index];\n        }\n    }\n    // Ideally we would push to a slice then hash, but there is no sha_slice\n    // Hardcode to 256 bytes for now\n    let mut hash = sha256_to_field(hash_input_flattened);\n    // Not having a 0 value hash for empty logs causes issues with empty txs\n    // used for padding. Returning early is currently unsupported.\n    // We always provide sorted logs here, so 0 being empty means all are empty.\n    if is_empty(logs[0]) {\n        hash = 0;\n    }\n    hash\n}\n\npub fn compute_tx_note_logs_hash(logs: [LogHash; MAX_NOTE_ENCRYPTED_LOGS_PER_TX]) -> Field {\n    // Convert each field element into a byte array and append the bytes to `hash_input_flattened`\n    let mut hash_input_flattened = [0; MAX_NOTE_ENCRYPTED_LOGS_PER_TX * 32];\n    for offset in 0..MAX_NOTE_ENCRYPTED_LOGS_PER_TX {\n        let input_as_bytes: [u8; 32] = logs[offset].value.to_be_bytes();\n        for byte_index in 0..32 {\n            hash_input_flattened[offset * 32 + byte_index] = input_as_bytes[byte_index];\n        }\n    }\n    // Ideally we would push to a slice then hash, but there is no sha_slice\n    // Hardcode to 256 bytes for now\n    let mut hash = sha256_to_field(hash_input_flattened);\n    // Not having a 0 value hash for empty logs causes issues with empty txs\n    // used for padding. Returning early is currently unsupported.\n    // We always provide sorted logs here, so 0 being empty means all are empty.\n    if is_empty(logs[0]) {\n        hash = 0;\n    }\n    hash\n}\n\npub fn pedersen_hash<let N: u32>(inputs: [Field; N], hash_index: u32) -> Field {\n    std::hash::pedersen_hash_with_separator(inputs, hash_index)\n}\n\npub fn poseidon2_hash<let N: u32>(inputs: [Field; N]) -> Field {\n    std::hash::poseidon2::Poseidon2::hash(inputs, N)\n}\n\n#[no_predicates]\npub fn poseidon2_hash_with_separator<let N: u32, T>(\n    inputs: [Field; N],\n    separator: T\n) -> Field where T: ToField {\n    // We manually hash the inputs here, since we cannot express with the type system a constant size inputs array of N + 1\n    let in_len = N + 1;\n    let two_pow_64 = 18446744073709551616;\n    let iv : Field = (in_len as Field) * two_pow_64;\n    let mut sponge = std::hash::poseidon2::Poseidon2::new(iv);\n    sponge.absorb(separator.to_field());\n\n    for i in 0..inputs.len() {\n        sponge.absorb(inputs[i]);\n    }\n\n    sponge.squeeze()\n}\n\npub fn poseidon2_hash_with_separator_slice<T>(inputs: [Field], separator: T) -> Field where T: ToField {\n    let in_len = inputs.len() + 1;\n    let two_pow_64 = 18446744073709551616;\n    let iv : Field = (in_len as Field) * two_pow_64;\n    let mut sponge = std::hash::poseidon2::Poseidon2::new(iv);\n    sponge.absorb(separator.to_field());\n\n    for i in 0..inputs.len() {\n        sponge.absorb(inputs[i]);\n    }\n\n    sponge.squeeze()\n}\n\n#[no_predicates]\npub fn poseidon2_hash_bytes<let N: u32>(inputs: [u8; N]) -> Field {\n    // We manually hash the inputs here, since we cannot express with the type system a constant size inputs array of Math.ceil(N/31)\n    let mut in_len = N / 31;\n    let mut has_padding = false;\n    if N % 31 != 0 {\n        in_len += 1;\n        has_padding = true;\n    }\n\n    let two_pow_64 = 18446744073709551616;\n    let iv : Field = (in_len as Field) * two_pow_64;\n    let mut sponge = std::hash::poseidon2::Poseidon2::new(iv);\n\n    let mut current_field = [0; 31];\n    for i in 0..inputs.len() {\n        let index = i % 31;\n        current_field[index] = inputs[i];\n        if index == 30 {\n            sponge.absorb(field_from_bytes(current_field, false));\n            current_field = [0; 31];\n        }\n    }\n    if has_padding {\n        sponge.absorb(field_from_bytes(current_field, false));\n    }\n\n    sponge.squeeze()\n}\n\n#[test]\nfn smoke_sha256_to_field() {\n    let full_buffer = [\n        0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19,\n        20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39,\n        40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59,\n        60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79,\n        80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99,\n        100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n        120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159\n    ];\n    let result = sha256_to_field(full_buffer);\n\n    assert(result == 0x448ebbc9e1a31220a2f3830c18eef61b9bd070e5084b7fa2a359fe729184c7);\n\n    // to show correctness of the current ver (truncate one byte) vs old ver (mod full bytes):\n    let result_bytes = std::hash::sha256(full_buffer);\n    let truncated_field = crate::utils::field::field_from_bytes_32_trunc(result_bytes);\n    assert(truncated_field == result);\n    let mod_res = result + (result_bytes[31] as Field);\n    assert(mod_res == 0x448ebbc9e1a31220a2f3830c18eef61b9bd070e5084b7fa2a359fe729184e0);\n}\n\n#[test]\nfn compute_l2_l1_hash() {\n    // All zeroes\n    let hash_result = compute_l2_to_l1_hash(AztecAddress::from_field(0), EthAddress::zero(), 0, 0, 0);\n    assert(hash_result == 0xb393978842a0fa3d3e1470196f098f473f9678e72463cb65ec4ab5581856c2);\n\n    // Non-zero case\n    let hash_result = compute_l2_to_l1_hash(AztecAddress::from_field(1), EthAddress::from_field(3), 5, 2, 4);\n    assert(hash_result == 0x3f88c1044a05e5340ed20466276500f6d45ca5603913b9091e957161734e16);\n}\n\n#[test]\nfn silo_l2_to_l1_message_matches_typescript() {\n    let version = 4;\n    let chainId = 5;\n\n    let hash = silo_l2_to_l1_message(\n        ScopedL2ToL1Message {\n        message: L2ToL1Message { recipient: EthAddress::from_field(1), content: 2, counter: 0 },\n        contract_address: AztecAddress::from_field(3)\n    },\n        version,\n        chainId\n    );\n\n    // The following value was generated by `l2_to_l1_message.test.ts`\n    let hash_from_typescript = 0x00c6155d69febb9d5039b374dd4f77bf57b7c881709aa524a18acaa0bd57476a;\n\n    assert_eq(hash, hash_from_typescript);\n}\n","path":"/home/serge/nargo/github.com/AztecProtocol/aztec-packages/aztec-packages-v0.57.0/noir-projects/noir-protocol-circuits/crates/types/src/hash.nr"},"212":{"source":"pub use dep::std::embedded_curve_ops::EmbeddedCurvePoint as Point;\nuse crate::{traits::{Deserialize, Empty, Hash, Serialize}, hash::poseidon2_hash};\n\nglobal POINT_LENGTH: u32 = 3;\n\nimpl Serialize<POINT_LENGTH> for Point {\n    fn serialize(self: Self) -> [Field; POINT_LENGTH] {\n        [self.x, self.y, self.is_infinite as Field]\n    }\n}\n\nimpl Hash for Point {\n    fn hash(self) -> Field {\n        poseidon2_hash(self.serialize())\n    }\n}\n\nimpl Empty for Point {\n    /// Note: Does not return a valid point on curve - instead represents an empty/\"unpopulated\" point struct (e.g.\n    /// empty/unpopulated value in an array of points).\n    fn empty() -> Self {\n        Point { x: 0, y: 0, is_infinite: false }\n    }\n}\n\nimpl Deserialize<POINT_LENGTH> for Point {\n    fn deserialize(serialized: [Field; POINT_LENGTH]) -> Point {\n        Point { x: serialized[0], y: serialized[1], is_infinite: serialized[2] as bool }\n    }\n}\n","path":"/home/serge/nargo/github.com/AztecProtocol/aztec-packages/aztec-packages-v0.57.0/noir-projects/noir-protocol-circuits/crates/types/src/point.nr"},"239":{"source":"pub fn field_from_bytes<let N: u32>(bytes: [u8; N], big_endian: bool) -> Field {\n    assert(bytes.len() < 32, \"field_from_bytes: N must be less than 32\");\n    let mut as_field = 0;\n    let mut offset = 1;\n    for i in 0..N {\n        let mut index = i;\n        if big_endian {\n            index = N - i - 1;\n        }\n        as_field += (bytes[index] as Field) * offset;\n        offset *= 256;\n    }\n\n    as_field\n}\n\n// Convert a 32 byte array to a field element by truncating the final byte\npub fn field_from_bytes_32_trunc(bytes32: [u8; 32]) -> Field {\n    // Convert it to a field element\n    let mut v = 1;\n    let mut high = 0 as Field;\n    let mut low = 0 as Field;\n\n    for i in 0..15 {\n        // covers bytes 16..30 (31 is truncated and ignored)\n        low = low + (bytes32[15 + 15 - i] as Field) * v;\n        v = v * 256;\n        // covers bytes 0..14\n        high = high + (bytes32[14 - i] as Field) * v;\n    }\n    // covers byte 15\n    low = low + (bytes32[15] as Field) * v;\n\n    low + high * v\n}\n\n// TODO to radix returns u8, so we cannot use bigger radixes. It'd be ideal to use a radix of the maximum range-constrained integer noir supports\npub fn full_field_less_than(lhs: Field, rhs: Field) -> bool {\n    lhs.lt(rhs)\n}\n\npub fn full_field_greater_than(lhs: Field, rhs: Field) -> bool {\n    rhs.lt(lhs)\n}\n\n#[test]\nunconstrained fn bytes_field_test() {\n    // Tests correctness of field_from_bytes_32_trunc against existing methods\n    // Bytes representing 0x543e0a6642ffeb8039296861765a53407bba62bd1c97ca43374de950bbe0a7\n    let inputs = [\n        84, 62, 10, 102, 66, 255, 235, 128, 57, 41, 104, 97, 118, 90, 83, 64, 123, 186, 98, 189, 28, 151, 202, 67, 55, 77, 233, 80, 187, 224, 167\n    ];\n    let field = field_from_bytes(inputs, true);\n    let return_bytes: [u8; 31] = field.to_be_bytes();\n    for i in 0..31 {\n        assert_eq(inputs[i], return_bytes[i]);\n    }\n    // 32 bytes - we remove the final byte, and check it matches the field\n    let inputs2 = [\n        84, 62, 10, 102, 66, 255, 235, 128, 57, 41, 104, 97, 118, 90, 83, 64, 123, 186, 98, 189, 28, 151, 202, 67, 55, 77, 233, 80, 187, 224, 167, 158\n    ];\n    let field2 = field_from_bytes_32_trunc(inputs2);\n    let return_bytes2: [u8; 31] = field.to_be_bytes();\n\n    for i in 0..31 {\n        assert_eq(return_bytes2[i], return_bytes[i]);\n    }\n    assert_eq(field2, field);\n}\n\n#[test]\nunconstrained fn max_field_test() {\n    // Tests the hardcoded value in constants.nr vs underlying modulus\n    // NB: We can't use 0-1 in constants.nr as it will be transpiled incorrectly to ts and sol constants files\n    let max_value = crate::constants::MAX_FIELD_VALUE;\n    assert_eq(max_value, 0 - 1);\n    // modulus == 0 is tested elsewhere, so below is more of a sanity check\n    let max_bytes: [u8; 32] = max_value.to_be_bytes();\n    let mod_bytes = std::field::modulus_be_bytes();\n    for i in 0..31 {\n        assert_eq(max_bytes[i], mod_bytes[i]);\n    }\n    assert_eq(max_bytes[31], mod_bytes[31] - 1);\n}\n","path":"/home/serge/nargo/github.com/AztecProtocol/aztec-packages/aztec-packages-v0.57.0/noir-projects/noir-protocol-circuits/crates/types/src/utils/field.nr"},"263":{"source":"global NULLIFIER_LEAF_PREIMAGE_LENGTH: u32 = 3;\n\nuse crate::{\n    abis::{read_request::ScopedReadRequest, side_effect::Readable}, hash::compute_siloed_nullifier,\n    merkle_tree::leaf_preimage::{LeafPreimage, IndexedTreeLeafPreimage}, traits::{Empty, Hash}\n};\n\npub struct NullifierLeafPreimage {\n    nullifier : Field,\n    next_nullifier :Field,\n    next_index : u32,\n}\n\nimpl Empty for NullifierLeafPreimage {\n    fn empty() -> Self {\n        Self { nullifier: 0, next_nullifier: 0, next_index: 0 }\n    }\n}\n\nimpl Hash for NullifierLeafPreimage {\n    fn hash(self) -> Field {\n        if self.is_empty() {\n            0\n        } else {\n            crate::hash::poseidon2_hash(self.serialize())\n        }\n    }\n}\n\nimpl LeafPreimage for NullifierLeafPreimage {\n    fn get_key(self) -> Field {\n        self.nullifier\n    }\n\n    fn as_leaf(self) -> Field {\n        self.hash()\n    }\n}\n\nimpl IndexedTreeLeafPreimage for NullifierLeafPreimage {\n    fn get_key(self) -> Field {\n        self.nullifier\n    }\n\n    fn get_next_key(self) -> Field {\n        self.next_nullifier\n    }\n\n    fn as_leaf(self) -> Field {\n        self.hash()\n    }\n}\n\nimpl Readable<ScopedReadRequest> for NullifierLeafPreimage {\n    fn assert_match_read_request(self, read_request: ScopedReadRequest) {\n        let siloed_value = compute_siloed_nullifier(read_request.contract_address, read_request.value());\n        assert_eq(self.nullifier, siloed_value, \"Value of the nullifier leaf does not match read request\");\n    }\n}\n\nimpl NullifierLeafPreimage {\n    pub fn is_empty(self) -> bool {\n        (self.nullifier == 0) & (self.next_nullifier == 0) & (self.next_index == 0)\n    }\n\n    pub fn serialize(self) -> [Field; NULLIFIER_LEAF_PREIMAGE_LENGTH] {\n        [self.nullifier, self.next_nullifier, self.next_index as Field]\n    }\n\n    pub fn deserialize(fields: [Field; NULLIFIER_LEAF_PREIMAGE_LENGTH]) -> Self {\n        Self { nullifier: fields[0], next_nullifier: fields[1], next_index: fields[2] as u32 }\n    }\n}\n\nimpl Eq for NullifierLeafPreimage {\n    fn eq(self, other: Self) -> bool {\n        (self.nullifier == other.nullifier)\n            & (self.next_nullifier == other.next_nullifier)\n            & (self.next_index == other.next_index)\n    }\n}\n\n#[test]\nfn serialization_of_empty() {\n    let item = NullifierLeafPreimage::empty();\n    let serialized = item.serialize();\n    let deserialized = NullifierLeafPreimage::deserialize(serialized);\n    assert(item.eq(deserialized));\n}\n","path":"/home/serge/nargo/github.com/AztecProtocol/aztec-packages/aztec-packages-v0.57.0/noir-projects/noir-protocol-circuits/crates/types/src/abis/nullifier_leaf_preimage.nr"},"302":{"source":"use crate::{\n    address::{AztecAddress, EthAddress}, abis::gas_fees::GasFees, constants::GLOBAL_VARIABLES_LENGTH,\n    traits::{Deserialize, Empty, Serialize}, utils::reader::Reader\n};\n\n// docs:start:global-variables\npub struct GlobalVariables {\n    chain_id : Field,\n    version : Field,\n    block_number : Field,\n    slot_number : Field,\n    timestamp : u64,\n    coinbase : EthAddress,\n    fee_recipient : AztecAddress,\n    gas_fees : GasFees\n}\n// docs:end:global-variables\n\nimpl GlobalVariables {\n    fn is_empty(self) -> bool {\n        (self.chain_id == 0)\n            & (self.version == 0)\n            & (self.block_number == 0)\n            & (self.slot_number == 0)\n            & (self.timestamp == 0)\n            & (self.coinbase.is_zero())\n            & (self.fee_recipient.is_zero())\n            & (self.gas_fees.is_empty())\n    }\n}\n\nimpl Serialize<GLOBAL_VARIABLES_LENGTH> for GlobalVariables {\n    fn serialize(self) -> [Field; GLOBAL_VARIABLES_LENGTH] {\n        let mut serialized: BoundedVec<Field, GLOBAL_VARIABLES_LENGTH> = BoundedVec::new();\n\n        serialized.push(self.chain_id);\n        serialized.push(self.version);\n        serialized.push(self.block_number);\n        serialized.push(self.slot_number);\n        serialized.push(self.timestamp as Field);\n        serialized.push(self.coinbase.to_field());\n        serialized.push(self.fee_recipient.to_field());\n        serialized.extend_from_array(self.gas_fees.serialize());\n\n        serialized.storage\n    }\n}\n\nimpl Deserialize<GLOBAL_VARIABLES_LENGTH> for GlobalVariables {\n    fn deserialize(serialized: [Field; GLOBAL_VARIABLES_LENGTH]) -> GlobalVariables {\n        let mut reader = Reader::new(serialized);\n        GlobalVariables {\n            chain_id: reader.read(),\n            version: reader.read(),\n            block_number: reader.read(),\n            slot_number: reader.read(),\n            timestamp: reader.read() as u64,\n            coinbase: EthAddress::from_field(reader.read()),\n            fee_recipient: AztecAddress::from_field(reader.read()),\n            gas_fees: reader.read_struct(GasFees::deserialize)\n        }\n    }\n}\n\nimpl Eq for GlobalVariables {\n    fn eq(self, other: GlobalVariables) -> bool {\n        (self.chain_id == other.chain_id)\n            & (self.version == other.version)\n            & (self.block_number == other.block_number)\n            & (self.slot_number == other.slot_number)\n            & (self.timestamp == other.timestamp)\n            & (self.coinbase == other.coinbase)\n            & (self.fee_recipient == other.fee_recipient)\n            & (self.gas_fees == other.gas_fees)\n    }\n}\n\nimpl Empty for GlobalVariables {\n    fn empty() -> Self {\n        Self {\n            chain_id: 0,\n            version: 0,\n            block_number: 0,\n            slot_number: 0,\n            timestamp: 0,\n            coinbase: EthAddress::empty(),\n            fee_recipient: AztecAddress::empty(),\n            gas_fees: GasFees::empty()\n        }\n    }\n}\n\n#[test]\nfn serialization_of_empty() {\n    let vars = GlobalVariables::empty();\n    let _serialized = vars.serialize();\n    let _deserialized = GlobalVariables::deserialize(_serialized);\n}\n","path":"/home/serge/nargo/github.com/AztecProtocol/aztec-packages/aztec-packages-v0.57.0/noir-projects/noir-protocol-circuits/crates/types/src/abis/global_variables.nr"},"316":{"source":"use crate::{\n    abis::{\n    append_only_tree_snapshot::{AppendOnlyTreeSnapshot, APPEND_ONLY_TREE_SNAPSHOT_LENGTH},\n    global_variables::GlobalVariables\n},\n    constants::{\n    GENERATOR_INDEX__BLOCK_HASH, GLOBAL_VARIABLES_LENGTH, HEADER_LENGTH, STATE_REFERENCE_LENGTH,\n    CONTENT_COMMITMENT_LENGTH\n},\n    hash::poseidon2_hash_with_separator, state_reference::StateReference,\n    traits::{Deserialize, Empty, Hash, Serialize}, utils::arr_copy_slice,\n    content_commitment::ContentCommitment\n};\n\n// docs:start:header\npub struct Header {\n    last_archive: AppendOnlyTreeSnapshot,\n    content_commitment: ContentCommitment,\n    state: StateReference,\n    global_variables: GlobalVariables,\n    total_fees: Field\n}\n// docs:end:header\n\nimpl Eq for Header {\n    fn eq(self, other: Self) -> bool {\n        self.last_archive.eq(other.last_archive)\n            & self.content_commitment.eq(other.content_commitment)\n            & self.state.eq(other.state)\n            & self.global_variables.eq(other.global_variables)\n            & self.total_fees.eq(other.total_fees)\n    }\n}\n\nimpl Serialize<HEADER_LENGTH> for Header {\n    fn serialize(self) -> [Field; HEADER_LENGTH] {\n        let mut fields: BoundedVec<Field, HEADER_LENGTH> = BoundedVec::new();\n\n        fields.extend_from_array(self.last_archive.serialize());\n        fields.extend_from_array(self.content_commitment.serialize());\n        fields.extend_from_array(self.state.serialize());\n        fields.extend_from_array(self.global_variables.serialize());\n        fields.push(self.total_fees);\n\n        fields.storage\n    }\n}\n\nimpl Deserialize<HEADER_LENGTH> for Header {\n    fn deserialize(serialized: [Field; HEADER_LENGTH]) -> Self {\n        let mut offset = 0;\n\n        let last_archive_fields = arr_copy_slice(serialized, [0; APPEND_ONLY_TREE_SNAPSHOT_LENGTH], offset);\n        offset = offset + APPEND_ONLY_TREE_SNAPSHOT_LENGTH;\n\n        let content_commitment_fields = arr_copy_slice(serialized, [0; CONTENT_COMMITMENT_LENGTH], offset);\n        offset = offset + CONTENT_COMMITMENT_LENGTH;\n\n        let state_fields = arr_copy_slice(serialized, [0; STATE_REFERENCE_LENGTH], offset);\n        offset = offset + STATE_REFERENCE_LENGTH;\n\n        let global_variables_fields = arr_copy_slice(serialized, [0; GLOBAL_VARIABLES_LENGTH], offset);\n        offset = offset + GLOBAL_VARIABLES_LENGTH;\n\n        let total_fees = serialized[offset];\n\n        Header {\n            last_archive: AppendOnlyTreeSnapshot::deserialize(last_archive_fields),\n            content_commitment: ContentCommitment::deserialize(content_commitment_fields),\n            state: StateReference::deserialize(state_fields),\n            global_variables: GlobalVariables::deserialize(global_variables_fields),\n            total_fees\n        }\n    }\n}\n\nimpl Empty for Header {\n    fn empty() -> Self {\n        Self {\n            last_archive: AppendOnlyTreeSnapshot::zero(),\n            content_commitment: ContentCommitment::empty(),\n            state: StateReference::empty(),\n            global_variables: GlobalVariables::empty(),\n            total_fees: 0\n        }\n    }\n}\n\nimpl Hash for Header {\n    fn hash(self) -> Field {\n        poseidon2_hash_with_separator(self.serialize(), GENERATOR_INDEX__BLOCK_HASH)\n    }\n}\n\n#[test]\nfn serialization_of_empty() {\n    let header = Header::empty();\n    let serialized = header.serialize();\n    let deserialized = Header::deserialize(serialized);\n    assert(header.eq(deserialized));\n}\n\n#[test]\nfn hash_smoke() {\n    let header = Header::empty();\n    let _hashed = header.hash();\n}\n\n#[test]\nfn empty_hash_is_zero() {\n    let header = Header::empty();\n    let hash = header.hash();\n\n    // Value from new_contract_data.test.ts \"computes empty hash\" test\n    let test_data_empty_hash = 0x1c97ed6fbc35f8b400d31bd38ce5cc938921e0cf2e20159d316f8c7011f9f42c;\n    assert_eq(hash, test_data_empty_hash);\n}\n","path":"/home/serge/nargo/github.com/AztecProtocol/aztec-packages/aztec-packages-v0.57.0/noir-projects/noir-protocol-circuits/crates/types/src/header.nr"},"321":{"source":"use crate::{constants::ETH_ADDRESS_LENGTH, traits::{Empty, ToField, Serialize, Deserialize}, utils};\n\npub struct EthAddress{\n    inner : Field\n}\n\nimpl Eq for EthAddress {\n    fn eq(self, other: Self) -> bool {\n        self.to_field() == other.to_field()\n    }\n}\n\nimpl Empty for EthAddress {\n    fn empty() -> Self {\n        Self { inner: 0 }\n    }\n}\n\nimpl ToField for EthAddress {\n    fn to_field(self) -> Field {\n        self.inner\n    }\n}\n\nimpl Serialize<ETH_ADDRESS_LENGTH> for EthAddress {\n    fn serialize(self: Self) -> [Field; ETH_ADDRESS_LENGTH] {\n        [self.inner]\n    }\n}\n\nimpl Deserialize<ETH_ADDRESS_LENGTH> for EthAddress {\n    fn deserialize(fields: [Field; ETH_ADDRESS_LENGTH]) -> Self {\n        EthAddress::from_field(fields[0])\n    }\n}\n\nimpl EthAddress {\n    pub fn zero() -> Self {\n        Self { inner: 0 }\n    }\n\n    pub fn from_field(field: Field) -> Self {\n        field.assert_max_bit_size(160);\n        Self { inner: field }\n    }\n\n    pub fn is_zero(self) -> bool {\n        self.inner == 0\n    }\n\n    pub fn assert_is_zero(self) {\n        assert(self.to_field() == 0);\n    }\n\n    pub fn conditional_assign(predicate: bool, lhs: Self, rhs: Self) -> Self {\n        let result = utils::conditional_assign(predicate, rhs.to_field(), lhs.to_field());\n        Self { inner: result }\n    }\n}\n","path":"/home/serge/nargo/github.com/AztecProtocol/aztec-packages/aztec-packages-v0.57.0/noir-projects/noir-protocol-circuits/crates/types/src/address/eth_address.nr"},"335":{"source":"use dep::aztec::{\n    note::utils::compute_note_hash_for_nullify, keys::getters::get_nsk_app, oracle::random::random,\n    prelude::{NullifiableNote, NoteHeader, PrivateContext},\n    protocol_types::{constants::GENERATOR_INDEX__NOTE_NULLIFIER, hash::poseidon2_hash_with_separator, traits::{Empty, Eq}},\n    macros::notes::partial_note\n};\n\n#[partial_note(quote { token_id})]\npub struct NFTNote {\n    // ID of the token\n    token_id: Field,\n    // The nullifying public key hash is used with the nsk_app to ensure that the note can be privately spent.\n    npk_m_hash: Field,\n    // Randomness of the note to hide its contents\n    randomness: Field,\n}\n\nimpl NullifiableNote for NFTNote {\n    fn compute_nullifier(self, context: &mut PrivateContext, note_hash_for_nullify: Field) -> Field {\n        let secret = context.request_nsk_app(self.npk_m_hash);\n        poseidon2_hash_with_separator(\n            [\n            note_hash_for_nullify,\n            secret\n        ],\n            GENERATOR_INDEX__NOTE_NULLIFIER as Field\n        )\n    }\n\n    unconstrained fn compute_nullifier_without_context(self) -> Field {\n        let note_hash_for_nullify = compute_note_hash_for_nullify(self);\n        let secret = get_nsk_app(self.npk_m_hash);\n        poseidon2_hash_with_separator(\n            [\n            note_hash_for_nullify,\n            secret\n        ],\n            GENERATOR_INDEX__NOTE_NULLIFIER as Field\n        )\n    }\n}\n\nimpl NFTNote {\n    pub fn new(token_id: Field, npk_m_hash: Field) -> Self {\n        // We use the randomness to preserve the privacy of the note recipient by preventing brute-forcing, so a\n        // malicious sender could use non-random values to make the note less private. But they already know the full\n        // note pre-image anyway, and so the recipient already trusts them to not disclose this information. We can\n        // therefore assume that the sender will cooperate in the random value generation.\n        let randomness = unsafe {\n            random()\n        };\n        NFTNote { token_id, npk_m_hash, randomness, header: NoteHeader::empty() }\n    }\n}\n\nimpl Eq for NFTNote {\n    fn eq(self, other: Self) -> bool {\n        (self.token_id == other.token_id)\n            & (self.npk_m_hash == other.npk_m_hash)\n            & (self.randomness == other.randomness)\n    }\n}\n","path":"/home/serge/nargo/github.com/AztecProtocol/aztec-packages/aztec-packages-v0.57.0/noir-projects/noir-contracts/contracts/nft_contract/src/types/nft_note.nr"}},"names":["main"],"brillig_names":["decompose_hint","lt_32_hint","lte_16_hint","directive_integer_quotient","directive_invert"]}